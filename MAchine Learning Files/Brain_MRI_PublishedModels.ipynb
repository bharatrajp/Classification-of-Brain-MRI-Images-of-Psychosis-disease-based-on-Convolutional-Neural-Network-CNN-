{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import math\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import copy\n",
    "\n",
    "import Models as published_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CF</th>\n",
       "      <th>FirstEpisodes_FEP__HealthyControl_HC_</th>\n",
       "      <th>FEP_binary</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Site 1</th>\n",
       "      <th>Site 2</th>\n",
       "      <th>Site 3</th>\n",
       "      <th>Site 4</th>\n",
       "      <th>Site 5</th>\n",
       "      <th>Site 6</th>\n",
       "      <th>Site 7</th>\n",
       "      <th>Euler</th>\n",
       "      <th>Test</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CF_001</td>\n",
       "      <td>FEP</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23.857632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CF_002</td>\n",
       "      <td>FEP</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28.952772</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CF_003</td>\n",
       "      <td>FEP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.199863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CF_004</td>\n",
       "      <td>FEP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.517454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CF_005</td>\n",
       "      <td>FEP</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39.101985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_CF FirstEpisodes_FEP__HealthyControl_HC_  FEP_binary  Diagnosis  \\\n",
       "0  CF_001                                   FEP           1          3   \n",
       "1  CF_002                                   FEP           1          3   \n",
       "2  CF_003                                   FEP           1          1   \n",
       "3  CF_004                                   FEP           1          1   \n",
       "4  CF_005                                   FEP           1          2   \n",
       "\n",
       "   Gender        Age  Site 1  Site 2  Site 3  Site 4  Site 5  Site 6  Site 7  \\\n",
       "0       0  23.857632       0       0       0       0       0       0       0   \n",
       "1       0  28.952772       0       0       0       0       0       0       0   \n",
       "2       0  20.199863       0       0       0       0       0       0       0   \n",
       "3       0  28.517454       0       0       0       0       0       0       0   \n",
       "4       1  39.101985       0       0       0       0       0       0       0   \n",
       "\n",
       "   Euler  Test  Class  \n",
       "0    -21     0      1  \n",
       "1    -33     1      1  \n",
       "2    -55     0      1  \n",
       "3    -26     1      1  \n",
       "4    -24     0      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DIR=\"./brains/\"\n",
    "\n",
    "data_df=pd.read_excel('Classification_clean.xlsx')\n",
    "\n",
    "data_df[\"Class\"]=data_df[\"Diagnosis\"]>0\n",
    "#data_df[\"Class\"]=data_df[\"FEP_binary\"]>0\n",
    "\n",
    "data_df.Class = data_df.Class.astype('int')\n",
    "\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Milano_MRI_Dataset(Dataset):\n",
    "    def __init__(self,df:pd.DataFrame,imfolder:str,train:bool = True, transforms=None):\n",
    "        self.df=df\n",
    "        self.imfolder=imfolder\n",
    "        self.train=train\n",
    "        #self.transforms=transforms\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        filename='w'+self.df.iloc[index]['ID_CF']+'_MRI_sMRI_'+self.df.iloc[index]['ID_CF']+'_brain.nii.gz';\n",
    "        \n",
    "        im_path=os.path.join(self.imfolder,filename)\n",
    "        \n",
    "        nimg = nb.load(im_path)\n",
    "        x = np.array(nimg.dataobj)\n",
    "        #x=nimg.get_fdata()\n",
    "        x = transforms.ToTensor()(x)\n",
    "        x=x.unsqueeze(0).type(torch.FloatTensor);\n",
    "        m=torch.mean(x)\n",
    "        s=torch.std(x)\n",
    "        x=(x-m)/s\n",
    "        \n",
    "        #x=torch.nn.functional.interpolate(x, size=(32,32,10), mode='trilinear)\n",
    "        \n",
    "        #if(self.transforms):\n",
    "        #    x=self.transforms(image=x)['image']\n",
    "        \n",
    "        if(self.train):\n",
    "            y=self.df.iloc[index]['Class']\n",
    "            return x,y\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_df[data_df['Test']==0]\n",
    "valid = data_df[data_df['Test']==1]\n",
    "\n",
    "# reset index on both dataframes\n",
    "train = train.reset_index(drop=True)\n",
    "valid = valid.reset_index(drop=True)\n",
    "\n",
    "train_targets = train.Class.values\n",
    "\n",
    "# targets for validation\n",
    "valid_targets = valid.Class.values\n",
    "\n",
    "train_dataset=Milano_MRI_Dataset(\n",
    "    df=train,\n",
    "    imfolder=BASE_DIR,\n",
    "    train=True,\n",
    "    transforms=None\n",
    ")\n",
    "\n",
    "valid_dataset=Milano_MRI_Dataset(\n",
    "    df=valid,\n",
    "    imfolder=BASE_DIR,\n",
    "    train=True,\n",
    "    transforms=None\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=10,\n",
    "    #num_workers=4,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=10,\n",
    "    #num_workers=4,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple 3D CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tufail_CNN - Brain Inf. (2021)\n",
    "# Oh_CNN - Front Psychiatry 2020 Feb 3;11:16\n",
    "# Zunair_CNN - Lecture Notes in Computer Science book series (LNIP,volume 12329), pp 156â€“168 (2020)\n",
    "# Li_CNN - Computerized Medical Imaging and Graphics 89 (2021) 101882\n",
    "# AlexNet_3D - Front. Neurol., 08 April 2020\n",
    "# VoxCNN - ISBI 2017, pp 835â€“838\n",
    "# VoxResNet21 - ISBI 2017, pp 835â€“838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [published_models.Tufail_CNN(2),published_models.Oh_CNN(2),published_models.Zunair_CNN(2),published_models.Li_CNN(2),published_models.AlexNet_3D(2),published_models.VoxCNN(2),published_models.VoxResNet21(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(datasets, dataloaders, model, criterion, optimizer, scheduler, num_epochs, device):\n",
    "    \n",
    "    since = time.time()\n",
    "    \n",
    "    train_history=np.zeros((4,num_epochs))\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs-1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        train_acc=0\n",
    "        \n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "            running_corrects_0 = 0.0\n",
    "            running_corrects_1 = 0.0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels=labels.to(device)\n",
    "                \n",
    "\n",
    "                # Zero out the grads\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                # Track history in train mode\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    model=model.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    #loss = criterion(outputs, labels.type(torch.LongTensor).unsqueeze(1).to(device))\n",
    "                    loss = criterion(outputs, labels.type(torch.LongTensor).to(device))\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                # Statistics\n",
    "                running_loss += loss.detach().item() *inputs.size(0)\n",
    "                running_corrects += torch.sum(preds.detach().cpu() == labels.detach().cpu()).item() \n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss/len(datasets[phase])\n",
    "            epoch_acc = running_corrects/len(datasets[phase])\n",
    "            \n",
    "            if phase=='train':\n",
    "                train_acc=epoch_acc\n",
    "                train_history[0,epoch]=epoch_loss\n",
    "                train_history[1,epoch]=epoch_acc\n",
    "            else:\n",
    "                train_history[2,epoch]=epoch_loss\n",
    "                train_history[3,epoch]=epoch_acc\n",
    "                \n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "        if train_acc >= (1-1e-6):\n",
    "            print('Early stopping')\n",
    "            break\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time()-since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4970, 1.0000])\n",
      "[338 168]\n"
     ]
    }
   ],
   "source": [
    "class_sample_count = np.array([len(np.where(train_targets == t)[0]) for t in np.unique(train_targets)])\n",
    "weight = 1. / class_sample_count\n",
    "class_weight=torch.from_numpy(weight)\n",
    "class_weight=class_weight/class_weight.max()\n",
    "class_weight=class_weight.type(torch.FloatTensor)\n",
    "print(class_weight)\n",
    "print(class_sample_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device('cuda:1')\n",
    "datasets={'train':train_dataset,'valid':valid_dataset}\n",
    "dataloaders={'train':train_loader,'valid':valid_loader}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: 0 of 7\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.6881 Acc: 0.5652\n",
      "valid Loss: 0.6901 Acc: 0.4048\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.6729 Acc: 0.6245\n",
      "valid Loss: 0.6631 Acc: 0.6905\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.6705 Acc: 0.6126\n",
      "valid Loss: 0.6280 Acc: 0.6964\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.6592 Acc: 0.6107\n",
      "valid Loss: 0.6169 Acc: 0.6845\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.6585 Acc: 0.6621\n",
      "valid Loss: 0.7605 Acc: 0.3274\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.6455 Acc: 0.6304\n",
      "valid Loss: 0.6397 Acc: 0.6964\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.6394 Acc: 0.6443\n",
      "valid Loss: 0.6044 Acc: 0.6905\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.6286 Acc: 0.6680\n",
      "valid Loss: 0.6042 Acc: 0.6845\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.6357 Acc: 0.6482\n",
      "valid Loss: 0.5812 Acc: 0.6786\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.6414 Acc: 0.6502\n",
      "valid Loss: 0.5647 Acc: 0.6905\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.6268 Acc: 0.6443\n",
      "valid Loss: 0.6813 Acc: 0.5119\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.6082 Acc: 0.6443\n",
      "valid Loss: 0.5935 Acc: 0.6667\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.6253 Acc: 0.6403\n",
      "valid Loss: 0.5367 Acc: 0.6726\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.6234 Acc: 0.6324\n",
      "valid Loss: 0.5537 Acc: 0.6786\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.5943 Acc: 0.6522\n",
      "valid Loss: 0.6114 Acc: 0.6429\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.5999 Acc: 0.6739\n",
      "valid Loss: 0.6002 Acc: 0.6131\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.5846 Acc: 0.6482\n",
      "valid Loss: 0.5789 Acc: 0.6607\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.5782 Acc: 0.6759\n",
      "valid Loss: 0.5359 Acc: 0.6905\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.5980 Acc: 0.6660\n",
      "valid Loss: 0.5739 Acc: 0.6607\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.5792 Acc: 0.6660\n",
      "valid Loss: 0.5540 Acc: 0.6845\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.5742 Acc: 0.6660\n",
      "valid Loss: 0.6501 Acc: 0.6667\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.5755 Acc: 0.6660\n",
      "valid Loss: 0.5505 Acc: 0.6667\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.5706 Acc: 0.6700\n",
      "valid Loss: 0.5611 Acc: 0.6548\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.5538 Acc: 0.6858\n",
      "valid Loss: 0.5492 Acc: 0.6905\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.5337 Acc: 0.7134\n",
      "valid Loss: 0.5995 Acc: 0.6786\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.5409 Acc: 0.7016\n",
      "valid Loss: 0.6824 Acc: 0.6667\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.5454 Acc: 0.6937\n",
      "valid Loss: 0.5824 Acc: 0.6726\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.5067 Acc: 0.7372\n",
      "valid Loss: 0.6191 Acc: 0.6845\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.5396 Acc: 0.6818\n",
      "valid Loss: 0.5986 Acc: 0.6250\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.5390 Acc: 0.7213\n",
      "valid Loss: 0.5995 Acc: 0.6548\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.5553 Acc: 0.6976\n",
      "valid Loss: 0.5877 Acc: 0.6429\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.5003 Acc: 0.7372\n",
      "valid Loss: 0.7981 Acc: 0.6310\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.5358 Acc: 0.7095\n",
      "valid Loss: 0.5871 Acc: 0.7083\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.5056 Acc: 0.7312\n",
      "valid Loss: 0.5557 Acc: 0.7143\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.5018 Acc: 0.7292\n",
      "valid Loss: 0.5472 Acc: 0.7083\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.4938 Acc: 0.7609\n",
      "valid Loss: 0.6756 Acc: 0.6548\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.4977 Acc: 0.7273\n",
      "valid Loss: 0.6376 Acc: 0.6964\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.4962 Acc: 0.7411\n",
      "valid Loss: 0.6685 Acc: 0.6905\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.4955 Acc: 0.7115\n",
      "valid Loss: 0.6008 Acc: 0.6905\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.4838 Acc: 0.7391\n",
      "valid Loss: 0.9313 Acc: 0.6845\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.4681 Acc: 0.7648\n",
      "valid Loss: 0.7196 Acc: 0.6964\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.4934 Acc: 0.7569\n",
      "valid Loss: 0.6699 Acc: 0.6250\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.4395 Acc: 0.7866\n",
      "valid Loss: 1.0058 Acc: 0.6905\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.4474 Acc: 0.7708\n",
      "valid Loss: 0.6324 Acc: 0.6369\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.4704 Acc: 0.7253\n",
      "valid Loss: 0.6232 Acc: 0.6667\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.4432 Acc: 0.7708\n",
      "valid Loss: 0.6043 Acc: 0.7024\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.4076 Acc: 0.7925\n",
      "valid Loss: 0.7331 Acc: 0.6012\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.3820 Acc: 0.8241\n",
      "valid Loss: 1.2338 Acc: 0.6726\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.4076 Acc: 0.8043\n",
      "valid Loss: 0.6133 Acc: 0.6548\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.3805 Acc: 0.7925\n",
      "valid Loss: 0.8905 Acc: 0.6786\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.3414 Acc: 0.8221\n",
      "valid Loss: 0.7789 Acc: 0.6786\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.3117 Acc: 0.8439\n",
      "valid Loss: 0.8263 Acc: 0.7143\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.2961 Acc: 0.8478\n",
      "valid Loss: 1.4145 Acc: 0.6786\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.3060 Acc: 0.8439\n",
      "valid Loss: 0.8147 Acc: 0.6964\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.2941 Acc: 0.8597\n",
      "valid Loss: 0.9932 Acc: 0.6845\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.2212 Acc: 0.8893\n",
      "valid Loss: 1.1820 Acc: 0.6845\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.1906 Acc: 0.9170\n",
      "valid Loss: 0.9003 Acc: 0.6964\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.1541 Acc: 0.9249\n",
      "valid Loss: 1.5235 Acc: 0.7143\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.1768 Acc: 0.9190\n",
      "valid Loss: 2.1086 Acc: 0.6845\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.1465 Acc: 0.9447\n",
      "valid Loss: 1.0088 Acc: 0.6726\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.1638 Acc: 0.9289\n",
      "valid Loss: 0.8835 Acc: 0.7024\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.0941 Acc: 0.9545\n",
      "valid Loss: 1.0934 Acc: 0.7440\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.1365 Acc: 0.9427\n",
      "valid Loss: 1.6115 Acc: 0.6488\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.1548 Acc: 0.9308\n",
      "valid Loss: 1.2289 Acc: 0.7024\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.0656 Acc: 0.9684\n",
      "valid Loss: 1.5287 Acc: 0.6845\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.0328 Acc: 0.9862\n",
      "valid Loss: 1.4339 Acc: 0.6786\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.0327 Acc: 0.9881\n",
      "valid Loss: 1.7660 Acc: 0.7083\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.0934 Acc: 0.9605\n",
      "valid Loss: 1.4813 Acc: 0.6905\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.0523 Acc: 0.9763\n",
      "valid Loss: 1.6526 Acc: 0.7321\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.0283 Acc: 0.9921\n",
      "valid Loss: 1.8208 Acc: 0.7202\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.2252 Acc: 0.9051\n",
      "valid Loss: 0.9286 Acc: 0.7202\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.0542 Acc: 0.9802\n",
      "valid Loss: 1.6130 Acc: 0.7024\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.0512 Acc: 0.9783\n",
      "valid Loss: 1.3869 Acc: 0.7321\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.0508 Acc: 0.9822\n",
      "valid Loss: 2.6126 Acc: 0.6667\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.0144 Acc: 0.9980\n",
      "valid Loss: 1.7934 Acc: 0.6786\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.0024 Acc: 1.0000\n",
      "valid Loss: 1.9561 Acc: 0.6786\n",
      "Early stopping\n",
      "Training complete in 65m 10s\n",
      "Best val Acc: 0.744048\n",
      "Total memory   :\t 25769803776\n",
      "Allocated memory   :\t 3867970560\n",
      "Free memory   :\t\t 21901833216\n",
      "Training model: 1 of 7\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.7746 Acc: 0.5237\n",
      "valid Loss: 0.6868 Acc: 0.6131\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.7211 Acc: 0.5692\n",
      "valid Loss: 0.6849 Acc: 0.5833\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.7761 Acc: 0.5455\n",
      "valid Loss: 0.6778 Acc: 0.5595\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.7642 Acc: 0.5395\n",
      "valid Loss: 0.7142 Acc: 0.3869\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.7193 Acc: 0.5850\n",
      "valid Loss: 0.7016 Acc: 0.4405\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.7380 Acc: 0.5455\n",
      "valid Loss: 0.7046 Acc: 0.4583\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.7399 Acc: 0.5257\n",
      "valid Loss: 0.7246 Acc: 0.4107\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.7237 Acc: 0.5731\n",
      "valid Loss: 0.6630 Acc: 0.6190\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.7254 Acc: 0.5553\n",
      "valid Loss: 0.6480 Acc: 0.6667\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.6900 Acc: 0.5850\n",
      "valid Loss: 0.6852 Acc: 0.5000\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.6916 Acc: 0.6067\n",
      "valid Loss: 0.6601 Acc: 0.6845\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.6883 Acc: 0.5909\n",
      "valid Loss: 0.6329 Acc: 0.6964\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.6901 Acc: 0.6126\n",
      "valid Loss: 0.7774 Acc: 0.6726\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.6830 Acc: 0.6028\n",
      "valid Loss: 0.6564 Acc: 0.6845\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.6633 Acc: 0.6245\n",
      "valid Loss: 0.6671 Acc: 0.6845\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.6608 Acc: 0.6443\n",
      "valid Loss: 0.6307 Acc: 0.6845\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6657 Acc: 0.6344\n",
      "valid Loss: 0.6418 Acc: 0.6667\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.6657 Acc: 0.6324\n",
      "valid Loss: 0.6725 Acc: 0.6131\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.6765 Acc: 0.6324\n",
      "valid Loss: 0.6339 Acc: 0.6786\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.6791 Acc: 0.6206\n",
      "valid Loss: 1.2465 Acc: 0.3274\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.6806 Acc: 0.6206\n",
      "valid Loss: 0.7052 Acc: 0.6667\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.6694 Acc: 0.6462\n",
      "valid Loss: 0.6289 Acc: 0.6845\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.6463 Acc: 0.6462\n",
      "valid Loss: 0.6207 Acc: 0.7024\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.6310 Acc: 0.6502\n",
      "valid Loss: 0.6144 Acc: 0.6726\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.6605 Acc: 0.6443\n",
      "valid Loss: 0.7806 Acc: 0.4107\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.6527 Acc: 0.6660\n",
      "valid Loss: 0.6920 Acc: 0.6726\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.6294 Acc: 0.6561\n",
      "valid Loss: 0.6291 Acc: 0.6964\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.6189 Acc: 0.6542\n",
      "valid Loss: 0.6121 Acc: 0.6964\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.6409 Acc: 0.6462\n",
      "valid Loss: 0.6190 Acc: 0.7143\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.5884 Acc: 0.6640\n",
      "valid Loss: 0.5964 Acc: 0.7202\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.5927 Acc: 0.6937\n",
      "valid Loss: 0.6359 Acc: 0.6845\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.6029 Acc: 0.6838\n",
      "valid Loss: 0.7288 Acc: 0.5536\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.6052 Acc: 0.6482\n",
      "valid Loss: 0.6253 Acc: 0.7262\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.5518 Acc: 0.7194\n",
      "valid Loss: 0.7650 Acc: 0.6726\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.5935 Acc: 0.6818\n",
      "valid Loss: 0.6521 Acc: 0.6310\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.5257 Acc: 0.7372\n",
      "valid Loss: 1.1350 Acc: 0.3690\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.5060 Acc: 0.7510\n",
      "valid Loss: 1.0583 Acc: 0.6726\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.5176 Acc: 0.7292\n",
      "valid Loss: 0.6824 Acc: 0.6786\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.4668 Acc: 0.7589\n",
      "valid Loss: 0.7370 Acc: 0.6905\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.4454 Acc: 0.7767\n",
      "valid Loss: 1.0919 Acc: 0.6845\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.4100 Acc: 0.8063\n",
      "valid Loss: 0.7758 Acc: 0.7024\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.4532 Acc: 0.7925\n",
      "valid Loss: 1.5019 Acc: 0.3571\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.4000 Acc: 0.8043\n",
      "valid Loss: 1.1237 Acc: 0.6786\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.3517 Acc: 0.8478\n",
      "valid Loss: 0.8609 Acc: 0.6250\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.3200 Acc: 0.8399\n",
      "valid Loss: 0.8764 Acc: 0.6964\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.3514 Acc: 0.8320\n",
      "valid Loss: 0.8190 Acc: 0.5952\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.2767 Acc: 0.8636\n",
      "valid Loss: 0.9030 Acc: 0.6607\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.3421 Acc: 0.8458\n",
      "valid Loss: 0.7746 Acc: 0.6964\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.2485 Acc: 0.8992\n",
      "valid Loss: 1.8982 Acc: 0.4643\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.2735 Acc: 0.8715\n",
      "valid Loss: 0.8034 Acc: 0.6964\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.2524 Acc: 0.8933\n",
      "valid Loss: 1.2578 Acc: 0.5357\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.1805 Acc: 0.9209\n",
      "valid Loss: 1.1685 Acc: 0.5833\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.1831 Acc: 0.9209\n",
      "valid Loss: 1.4998 Acc: 0.5238\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.2385 Acc: 0.9032\n",
      "valid Loss: 0.8678 Acc: 0.6845\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.2069 Acc: 0.9170\n",
      "valid Loss: 1.2050 Acc: 0.6726\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.2035 Acc: 0.9190\n",
      "valid Loss: 3.4041 Acc: 0.3393\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.1761 Acc: 0.9289\n",
      "valid Loss: 0.9984 Acc: 0.6250\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.1428 Acc: 0.9407\n",
      "valid Loss: 1.0017 Acc: 0.6429\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.1515 Acc: 0.9427\n",
      "valid Loss: 1.2037 Acc: 0.6012\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.1460 Acc: 0.9387\n",
      "valid Loss: 1.3549 Acc: 0.6905\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.1347 Acc: 0.9427\n",
      "valid Loss: 1.6608 Acc: 0.6786\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.1117 Acc: 0.9565\n",
      "valid Loss: 2.3128 Acc: 0.4762\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.1220 Acc: 0.9644\n",
      "valid Loss: 1.0297 Acc: 0.6667\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.1083 Acc: 0.9704\n",
      "valid Loss: 1.0155 Acc: 0.6667\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.1010 Acc: 0.9664\n",
      "valid Loss: 1.3295 Acc: 0.6905\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.1221 Acc: 0.9545\n",
      "valid Loss: 1.1204 Acc: 0.6726\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.1078 Acc: 0.9585\n",
      "valid Loss: 1.2578 Acc: 0.6905\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.1239 Acc: 0.9605\n",
      "valid Loss: 1.0006 Acc: 0.6667\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.1053 Acc: 0.9704\n",
      "valid Loss: 2.3136 Acc: 0.4464\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.0757 Acc: 0.9723\n",
      "valid Loss: 0.9665 Acc: 0.6964\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.0695 Acc: 0.9783\n",
      "valid Loss: 1.8205 Acc: 0.6964\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.0976 Acc: 0.9625\n",
      "valid Loss: 1.5396 Acc: 0.6905\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.0765 Acc: 0.9684\n",
      "valid Loss: 1.6880 Acc: 0.5714\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.1434 Acc: 0.9328\n",
      "valid Loss: 1.6981 Acc: 0.6905\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.0677 Acc: 0.9822\n",
      "valid Loss: 1.1609 Acc: 0.6369\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.0784 Acc: 0.9763\n",
      "valid Loss: 1.8748 Acc: 0.6905\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.1391 Acc: 0.9545\n",
      "valid Loss: 4.1268 Acc: 0.6726\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.0891 Acc: 0.9684\n",
      "valid Loss: 1.4071 Acc: 0.6012\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.1130 Acc: 0.9644\n",
      "valid Loss: 2.0104 Acc: 0.4464\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.1045 Acc: 0.9605\n",
      "valid Loss: 1.2474 Acc: 0.6131\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.1217 Acc: 0.9565\n",
      "valid Loss: 0.9902 Acc: 0.6905\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.1062 Acc: 0.9664\n",
      "valid Loss: 8.3644 Acc: 0.3274\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.1406 Acc: 0.9486\n",
      "valid Loss: 1.2990 Acc: 0.6726\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.0771 Acc: 0.9723\n",
      "valid Loss: 1.2107 Acc: 0.6964\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.0831 Acc: 0.9743\n",
      "valid Loss: 1.4651 Acc: 0.6667\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.0675 Acc: 0.9743\n",
      "valid Loss: 1.9715 Acc: 0.6786\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.0684 Acc: 0.9783\n",
      "valid Loss: 1.2327 Acc: 0.6667\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.0761 Acc: 0.9763\n",
      "valid Loss: 1.2413 Acc: 0.6488\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.0758 Acc: 0.9763\n",
      "valid Loss: 1.2983 Acc: 0.6488\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.0820 Acc: 0.9704\n",
      "valid Loss: 1.3416 Acc: 0.6845\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.0725 Acc: 0.9684\n",
      "valid Loss: 1.2973 Acc: 0.6548\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.0657 Acc: 0.9822\n",
      "valid Loss: 1.5977 Acc: 0.6964\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.0621 Acc: 0.9802\n",
      "valid Loss: 1.1532 Acc: 0.6905\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n",
      "train Loss: 0.0543 Acc: 0.9802\n",
      "valid Loss: 1.6104 Acc: 0.6905\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.0876 Acc: 0.9625\n",
      "valid Loss: 1.2616 Acc: 0.6845\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.0648 Acc: 0.9723\n",
      "valid Loss: 1.7470 Acc: 0.6905\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.0574 Acc: 0.9763\n",
      "valid Loss: 1.3392 Acc: 0.6905\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.0821 Acc: 0.9743\n",
      "valid Loss: 2.3655 Acc: 0.6786\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.0453 Acc: 0.9862\n",
      "valid Loss: 1.2627 Acc: 0.6667\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.0363 Acc: 0.9901\n",
      "valid Loss: 1.4224 Acc: 0.5893\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.0578 Acc: 0.9763\n",
      "valid Loss: 1.4760 Acc: 0.7083\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.0782 Acc: 0.9723\n",
      "valid Loss: 1.2627 Acc: 0.6667\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.0299 Acc: 0.9862\n",
      "valid Loss: 1.2645 Acc: 0.6310\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.0302 Acc: 0.9901\n",
      "valid Loss: 1.3338 Acc: 0.6488\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.0362 Acc: 0.9901\n",
      "valid Loss: 1.3335 Acc: 0.6548\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.0491 Acc: 0.9842\n",
      "valid Loss: 1.2504 Acc: 0.7024\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.0365 Acc: 0.9822\n",
      "valid Loss: 1.2037 Acc: 0.6786\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.0251 Acc: 0.9901\n",
      "valid Loss: 1.3113 Acc: 0.7143\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.0513 Acc: 0.9802\n",
      "valid Loss: 1.2106 Acc: 0.7024\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.0262 Acc: 0.9960\n",
      "valid Loss: 1.3378 Acc: 0.7083\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.0154 Acc: 0.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 1.2686 Acc: 0.6786\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9921\n",
      "valid Loss: 1.3638 Acc: 0.6905\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "train Loss: 0.0325 Acc: 0.9921\n",
      "valid Loss: 1.3050 Acc: 0.6607\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "train Loss: 0.0233 Acc: 0.9960\n",
      "valid Loss: 1.3038 Acc: 0.6845\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "train Loss: 0.0279 Acc: 0.9941\n",
      "valid Loss: 1.2841 Acc: 0.6726\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "train Loss: 0.0345 Acc: 0.9862\n",
      "valid Loss: 1.3246 Acc: 0.6726\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "train Loss: 0.0461 Acc: 0.9862\n",
      "valid Loss: 1.3627 Acc: 0.6905\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "train Loss: 0.0306 Acc: 0.9881\n",
      "valid Loss: 1.3079 Acc: 0.6667\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "train Loss: 0.0518 Acc: 0.9802\n",
      "valid Loss: 1.4570 Acc: 0.7024\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "train Loss: 0.0423 Acc: 0.9881\n",
      "valid Loss: 1.3227 Acc: 0.6905\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "train Loss: 0.0236 Acc: 0.9921\n",
      "valid Loss: 1.3531 Acc: 0.6964\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "train Loss: 0.0209 Acc: 0.9921\n",
      "valid Loss: 1.3665 Acc: 0.6964\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "train Loss: 0.0433 Acc: 0.9862\n",
      "valid Loss: 1.3200 Acc: 0.7024\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "train Loss: 0.0238 Acc: 0.9921\n",
      "valid Loss: 1.4111 Acc: 0.6964\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "train Loss: 0.0198 Acc: 0.9921\n",
      "valid Loss: 1.4302 Acc: 0.7083\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "train Loss: 0.0220 Acc: 0.9941\n",
      "valid Loss: 1.3900 Acc: 0.7143\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "train Loss: 0.0159 Acc: 0.9980\n",
      "valid Loss: 1.3069 Acc: 0.6786\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "train Loss: 0.0216 Acc: 0.9921\n",
      "valid Loss: 1.3848 Acc: 0.6845\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "train Loss: 0.0136 Acc: 0.9980\n",
      "valid Loss: 1.4008 Acc: 0.7143\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "train Loss: 0.0214 Acc: 0.9881\n",
      "valid Loss: 1.3948 Acc: 0.7024\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "train Loss: 0.0194 Acc: 0.9960\n",
      "valid Loss: 1.2675 Acc: 0.6905\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "train Loss: 0.0213 Acc: 0.9941\n",
      "valid Loss: 1.3381 Acc: 0.6905\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "train Loss: 0.0110 Acc: 0.9960\n",
      "valid Loss: 1.3301 Acc: 0.6845\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "train Loss: 0.0266 Acc: 0.9921\n",
      "valid Loss: 1.4503 Acc: 0.7202\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "train Loss: 0.0319 Acc: 0.9881\n",
      "valid Loss: 1.3261 Acc: 0.7143\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "train Loss: 0.0132 Acc: 0.9960\n",
      "valid Loss: 1.3841 Acc: 0.7083\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "train Loss: 0.0233 Acc: 0.9921\n",
      "valid Loss: 1.3036 Acc: 0.6845\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "train Loss: 0.0302 Acc: 0.9901\n",
      "valid Loss: 1.3165 Acc: 0.7083\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "train Loss: 0.0212 Acc: 0.9960\n",
      "valid Loss: 1.2915 Acc: 0.6964\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "train Loss: 0.0220 Acc: 0.9901\n",
      "valid Loss: 1.2774 Acc: 0.7024\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "train Loss: 0.0368 Acc: 0.9881\n",
      "valid Loss: 1.3886 Acc: 0.7202\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "train Loss: 0.0363 Acc: 0.9881\n",
      "valid Loss: 1.3967 Acc: 0.6964\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "train Loss: 0.0096 Acc: 0.9980\n",
      "valid Loss: 1.3615 Acc: 0.6786\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "train Loss: 0.0349 Acc: 0.9842\n",
      "valid Loss: 1.3368 Acc: 0.6845\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "train Loss: 0.0356 Acc: 0.9881\n",
      "valid Loss: 1.6799 Acc: 0.6964\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "train Loss: 0.0407 Acc: 0.9921\n",
      "valid Loss: 1.5214 Acc: 0.6905\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "train Loss: 0.0353 Acc: 0.9921\n",
      "valid Loss: 1.4820 Acc: 0.7024\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "train Loss: 0.0306 Acc: 0.9901\n",
      "valid Loss: 1.3432 Acc: 0.6845\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "train Loss: 0.0227 Acc: 0.9921\n",
      "valid Loss: 1.4571 Acc: 0.7083\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "train Loss: 0.0286 Acc: 0.9881\n",
      "valid Loss: 1.3892 Acc: 0.6845\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "train Loss: 0.0127 Acc: 0.9960\n",
      "valid Loss: 1.4653 Acc: 0.7083\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "train Loss: 0.0163 Acc: 0.9960\n",
      "valid Loss: 1.5969 Acc: 0.7024\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "train Loss: 0.0105 Acc: 0.9941\n",
      "valid Loss: 1.4710 Acc: 0.7083\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "train Loss: 0.0136 Acc: 0.9960\n",
      "valid Loss: 1.3171 Acc: 0.6726\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "train Loss: 0.0320 Acc: 0.9921\n",
      "valid Loss: 1.6464 Acc: 0.6964\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "train Loss: 0.0113 Acc: 0.9980\n",
      "valid Loss: 1.4856 Acc: 0.7024\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "train Loss: 0.0374 Acc: 0.9842\n",
      "valid Loss: 1.5395 Acc: 0.6964\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "train Loss: 0.0077 Acc: 1.0000\n",
      "valid Loss: 1.4200 Acc: 0.6905\n",
      "Early stopping\n",
      "Training complete in 88m 50s\n",
      "Best val Acc: 0.726190\n",
      "Total memory   :\t 25769803776\n",
      "Allocated memory   :\t 2704136704\n",
      "Free memory   :\t\t 23065667072\n",
      "Training model: 2 of 7\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.7802 Acc: 0.5850\n",
      "valid Loss: 0.6780 Acc: 0.6845\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.6692 Acc: 0.6502\n",
      "valid Loss: 0.6064 Acc: 0.6845\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.6227 Acc: 0.6561\n",
      "valid Loss: 0.7178 Acc: 0.6131\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.5966 Acc: 0.6680\n",
      "valid Loss: 0.6630 Acc: 0.6786\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.5784 Acc: 0.7055\n",
      "valid Loss: 0.5663 Acc: 0.6786\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.4702 Acc: 0.8004\n",
      "valid Loss: 0.6500 Acc: 0.6964\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.3199 Acc: 0.8656\n",
      "valid Loss: 0.6157 Acc: 0.6607\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.2521 Acc: 0.9032\n",
      "valid Loss: 1.0799 Acc: 0.7083\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.0805 Acc: 0.9921\n",
      "valid Loss: 0.7707 Acc: 0.7500\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.0132 Acc: 1.0000\n",
      "valid Loss: 0.8265 Acc: 0.7262\n",
      "Early stopping\n",
      "Training complete in 4m 34s\n",
      "Best val Acc: 0.750000\n",
      "Total memory   :\t 25769803776\n",
      "Allocated memory   :\t 3245886976\n",
      "Free memory   :\t\t 22523916800\n",
      "Training model: 3 of 7\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.6952 Acc: 0.3399\n",
      "valid Loss: 0.6920 Acc: 0.6845\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.6936 Acc: 0.5178\n",
      "valid Loss: 0.6920 Acc: 0.3333\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.6878 Acc: 0.5435\n",
      "valid Loss: 0.6629 Acc: 0.6607\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.6707 Acc: 0.6462\n",
      "valid Loss: 0.6453 Acc: 0.6845\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.6479 Acc: 0.6462\n",
      "valid Loss: 0.6368 Acc: 0.6786\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.6559 Acc: 0.6482\n",
      "valid Loss: 0.6404 Acc: 0.6726\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.6507 Acc: 0.6621\n",
      "valid Loss: 0.6410 Acc: 0.6845\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.6450 Acc: 0.6640\n",
      "valid Loss: 0.6511 Acc: 0.6488\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.6471 Acc: 0.6818\n",
      "valid Loss: 0.6484 Acc: 0.6488\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.6219 Acc: 0.6561\n",
      "valid Loss: 0.6263 Acc: 0.6726\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.6229 Acc: 0.6601\n",
      "valid Loss: 0.6280 Acc: 0.6250\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.6197 Acc: 0.6917\n",
      "valid Loss: 0.6315 Acc: 0.6488\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.6128 Acc: 0.6798\n",
      "valid Loss: 0.6382 Acc: 0.6429\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.5874 Acc: 0.6976\n",
      "valid Loss: 0.6199 Acc: 0.6905\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.5863 Acc: 0.7036\n",
      "valid Loss: 0.6907 Acc: 0.5714\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.5777 Acc: 0.7055\n",
      "valid Loss: 0.6482 Acc: 0.6310\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.5353 Acc: 0.7332\n",
      "valid Loss: 0.5985 Acc: 0.6786\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.5022 Acc: 0.7530\n",
      "valid Loss: 0.5868 Acc: 0.6964\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.4620 Acc: 0.7589\n",
      "valid Loss: 0.6830 Acc: 0.7202\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.5051 Acc: 0.7451\n",
      "valid Loss: 0.5892 Acc: 0.7262\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.3685 Acc: 0.8557\n",
      "valid Loss: 0.6776 Acc: 0.7381\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.3174 Acc: 0.8715\n",
      "valid Loss: 0.7123 Acc: 0.7381\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.2810 Acc: 0.8972\n",
      "valid Loss: 0.6224 Acc: 0.7321\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.2434 Acc: 0.9111\n",
      "valid Loss: 0.8838 Acc: 0.7381\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.2403 Acc: 0.9032\n",
      "valid Loss: 0.6365 Acc: 0.7262\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.1339 Acc: 0.9625\n",
      "valid Loss: 0.7103 Acc: 0.7202\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.0870 Acc: 0.9783\n",
      "valid Loss: 0.7428 Acc: 0.6964\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.0694 Acc: 0.9881\n",
      "valid Loss: 1.1081 Acc: 0.7262\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.0397 Acc: 0.9941\n",
      "valid Loss: 0.8755 Acc: 0.7024\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.0315 Acc: 0.9980\n",
      "valid Loss: 1.1381 Acc: 0.7500\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.0311 Acc: 0.9941\n",
      "valid Loss: 1.2275 Acc: 0.7679\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.0197 Acc: 1.0000\n",
      "valid Loss: 1.0157 Acc: 0.7202\n",
      "Early stopping\n",
      "Training complete in 24m 33s\n",
      "Best val Acc: 0.767857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory   :\t 25769803776\n",
      "Allocated memory   :\t 1472589312\n",
      "Free memory   :\t\t 24297214464\n",
      "Training model: 4 of 7\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.6969 Acc: 0.6383\n",
      "valid Loss: 0.6952 Acc: 0.3274\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.6973 Acc: 0.6206\n",
      "valid Loss: 0.6900 Acc: 0.6726\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.6944 Acc: 0.6324\n",
      "valid Loss: 0.6871 Acc: 0.6726\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.6936 Acc: 0.6680\n",
      "valid Loss: 0.6874 Acc: 0.6726\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.6935 Acc: 0.6285\n",
      "valid Loss: 0.6872 Acc: 0.6726\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.6975 Acc: 0.6166\n",
      "valid Loss: 0.6972 Acc: 0.3274\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.6945 Acc: 0.6561\n",
      "valid Loss: 0.6869 Acc: 0.6726\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.6926 Acc: 0.6680\n",
      "valid Loss: 0.6924 Acc: 0.6726\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.6938 Acc: 0.5810\n",
      "valid Loss: 0.6868 Acc: 0.6726\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.7027 Acc: 0.6304\n",
      "valid Loss: 0.6867 Acc: 0.6726\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.6967 Acc: 0.6462\n",
      "valid Loss: 0.6858 Acc: 0.6726\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.6956 Acc: 0.4901\n",
      "valid Loss: 0.6866 Acc: 0.6726\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.7024 Acc: 0.6047\n",
      "valid Loss: 0.6919 Acc: 0.6726\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.7646 Acc: 0.6640\n",
      "valid Loss: 0.7181 Acc: 0.3274\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.7236 Acc: 0.4862\n",
      "valid Loss: 0.6872 Acc: 0.6726\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.7050 Acc: 0.5356\n",
      "valid Loss: 0.6564 Acc: 0.6905\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.7065 Acc: 0.5573\n",
      "valid Loss: 0.6910 Acc: 0.6310\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.6800 Acc: 0.6047\n",
      "valid Loss: 0.6751 Acc: 0.6667\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.6933 Acc: 0.5455\n",
      "valid Loss: 0.6909 Acc: 0.6607\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.6910 Acc: 0.6798\n",
      "valid Loss: 0.6870 Acc: 0.6786\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.6833 Acc: 0.6344\n",
      "valid Loss: 0.6744 Acc: 0.6190\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.6865 Acc: 0.6364\n",
      "valid Loss: 0.6688 Acc: 0.6310\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.6761 Acc: 0.6344\n",
      "valid Loss: 0.6848 Acc: 0.6310\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.6779 Acc: 0.5415\n",
      "valid Loss: 0.6943 Acc: 0.3333\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.6840 Acc: 0.6166\n",
      "valid Loss: 0.7099 Acc: 0.3929\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.6856 Acc: 0.6443\n",
      "valid Loss: 0.6864 Acc: 0.5417\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.6878 Acc: 0.6304\n",
      "valid Loss: 0.6835 Acc: 0.5714\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.6729 Acc: 0.6462\n",
      "valid Loss: 0.6698 Acc: 0.6012\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.6582 Acc: 0.6186\n",
      "valid Loss: 0.6542 Acc: 0.6190\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.6684 Acc: 0.5791\n",
      "valid Loss: 0.6573 Acc: 0.6786\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.6857 Acc: 0.6304\n",
      "valid Loss: 0.6546 Acc: 0.6786\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.6792 Acc: 0.6186\n",
      "valid Loss: 0.6699 Acc: 0.6488\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.6768 Acc: 0.6285\n",
      "valid Loss: 0.6847 Acc: 0.5119\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.6578 Acc: 0.6502\n",
      "valid Loss: 0.6571 Acc: 0.6131\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.6648 Acc: 0.6462\n",
      "valid Loss: 0.7202 Acc: 0.3512\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.6717 Acc: 0.6225\n",
      "valid Loss: 0.6777 Acc: 0.5893\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.6626 Acc: 0.6146\n",
      "valid Loss: 0.6509 Acc: 0.6905\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.6490 Acc: 0.6917\n",
      "valid Loss: 0.7094 Acc: 0.5357\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.6474 Acc: 0.6719\n",
      "valid Loss: 0.6328 Acc: 0.6845\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.6619 Acc: 0.6660\n",
      "valid Loss: 0.6566 Acc: 0.6845\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.6690 Acc: 0.6522\n",
      "valid Loss: 0.6763 Acc: 0.5952\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.6495 Acc: 0.6779\n",
      "valid Loss: 0.6547 Acc: 0.6786\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.6521 Acc: 0.6818\n",
      "valid Loss: 0.6406 Acc: 0.6488\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.6547 Acc: 0.6621\n",
      "valid Loss: 0.6453 Acc: 0.6726\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.6468 Acc: 0.6798\n",
      "valid Loss: 0.6431 Acc: 0.6607\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.6532 Acc: 0.6957\n",
      "valid Loss: 0.6628 Acc: 0.6310\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.6456 Acc: 0.6581\n",
      "valid Loss: 0.6331 Acc: 0.6905\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.6611 Acc: 0.6522\n",
      "valid Loss: 0.6403 Acc: 0.6131\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.6405 Acc: 0.6818\n",
      "valid Loss: 0.6257 Acc: 0.6726\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.6312 Acc: 0.6818\n",
      "valid Loss: 0.6193 Acc: 0.6667\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.6394 Acc: 0.6561\n",
      "valid Loss: 0.6360 Acc: 0.6190\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.6313 Acc: 0.6719\n",
      "valid Loss: 0.6168 Acc: 0.6369\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.6302 Acc: 0.6976\n",
      "valid Loss: 0.6336 Acc: 0.6310\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.6283 Acc: 0.6996\n",
      "valid Loss: 0.6314 Acc: 0.6131\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.6352 Acc: 0.6996\n",
      "valid Loss: 0.6390 Acc: 0.6667\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.6341 Acc: 0.7115\n",
      "valid Loss: 0.6141 Acc: 0.6726\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.6139 Acc: 0.6818\n",
      "valid Loss: 0.6177 Acc: 0.6250\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.6198 Acc: 0.6779\n",
      "valid Loss: 0.6374 Acc: 0.6310\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.6187 Acc: 0.6957\n",
      "valid Loss: 0.6183 Acc: 0.6190\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.6186 Acc: 0.7115\n",
      "valid Loss: 0.6364 Acc: 0.6786\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.6283 Acc: 0.6976\n",
      "valid Loss: 0.6381 Acc: 0.6250\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.6117 Acc: 0.6779\n",
      "valid Loss: 0.6065 Acc: 0.6488\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.6135 Acc: 0.6206\n",
      "valid Loss: 0.6215 Acc: 0.6369\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.6175 Acc: 0.7134\n",
      "valid Loss: 0.6406 Acc: 0.6131\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.6057 Acc: 0.7036\n",
      "valid Loss: 0.6184 Acc: 0.6905\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.5806 Acc: 0.6976\n",
      "valid Loss: 0.6220 Acc: 0.6190\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.5856 Acc: 0.6858\n",
      "valid Loss: 0.5934 Acc: 0.6726\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.5870 Acc: 0.6680\n",
      "valid Loss: 0.6340 Acc: 0.6131\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.6461 Acc: 0.6462\n",
      "valid Loss: 0.6202 Acc: 0.6845\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.5949 Acc: 0.6759\n",
      "valid Loss: 0.6224 Acc: 0.6131\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.6256 Acc: 0.6897\n",
      "valid Loss: 0.6027 Acc: 0.7143\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 9.1046 Acc: 0.5613\n",
      "valid Loss: 4.5702 Acc: 0.3274\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 3.8909 Acc: 0.4921\n",
      "valid Loss: 4.3028 Acc: 0.3274\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 1.4014 Acc: 0.5692\n",
      "valid Loss: 1.0231 Acc: 0.3274\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.9204 Acc: 0.5237\n",
      "valid Loss: 0.6589 Acc: 0.6905\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.7310 Acc: 0.5652\n",
      "valid Loss: 0.7605 Acc: 0.6667\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.7595 Acc: 0.5534\n",
      "valid Loss: 0.6720 Acc: 0.6726\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.7052 Acc: 0.5968\n",
      "valid Loss: 0.6562 Acc: 0.6429\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.6947 Acc: 0.6126\n",
      "valid Loss: 0.6625 Acc: 0.6250\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.7199 Acc: 0.5988\n",
      "valid Loss: 0.6621 Acc: 0.6131\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.6934 Acc: 0.6087\n",
      "valid Loss: 0.8430 Acc: 0.3274\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.7340 Acc: 0.5810\n",
      "valid Loss: 0.6679 Acc: 0.6310\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.7017 Acc: 0.5870\n",
      "valid Loss: 0.6560 Acc: 0.6190\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.6859 Acc: 0.5968\n",
      "valid Loss: 0.6908 Acc: 0.5536\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.6854 Acc: 0.5988\n",
      "valid Loss: 0.6896 Acc: 0.5893\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.6721 Acc: 0.6542\n",
      "valid Loss: 0.6785 Acc: 0.6726\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.6793 Acc: 0.6364\n",
      "valid Loss: 0.6553 Acc: 0.6250\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.6848 Acc: 0.6206\n",
      "valid Loss: 0.6596 Acc: 0.6369\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.6903 Acc: 0.5909\n",
      "valid Loss: 0.6532 Acc: 0.6786\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.7000 Acc: 0.5909\n",
      "valid Loss: 0.7255 Acc: 0.3571\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.6773 Acc: 0.6245\n",
      "valid Loss: 0.7185 Acc: 0.3810\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.6670 Acc: 0.6107\n",
      "valid Loss: 0.6529 Acc: 0.6726\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.6723 Acc: 0.6206\n",
      "valid Loss: 0.6611 Acc: 0.6190\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6851 Acc: 0.6087\n",
      "valid Loss: 0.7384 Acc: 0.4940\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5909\n",
      "valid Loss: 0.6512 Acc: 0.6786\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.6944 Acc: 0.5949\n",
      "valid Loss: 0.6476 Acc: 0.6726\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.6634 Acc: 0.6462\n",
      "valid Loss: 0.6444 Acc: 0.6667\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.6785 Acc: 0.6087\n",
      "valid Loss: 0.6833 Acc: 0.5893\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.6783 Acc: 0.6324\n",
      "valid Loss: 0.6479 Acc: 0.6310\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.6651 Acc: 0.6522\n",
      "valid Loss: 0.6467 Acc: 0.6786\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.6629 Acc: 0.6285\n",
      "valid Loss: 0.6518 Acc: 0.6250\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.6550 Acc: 0.6304\n",
      "valid Loss: 0.6505 Acc: 0.6310\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.6552 Acc: 0.6680\n",
      "valid Loss: 0.6495 Acc: 0.6429\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.6550 Acc: 0.6423\n",
      "valid Loss: 0.6515 Acc: 0.6250\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.6461 Acc: 0.6462\n",
      "valid Loss: 0.6494 Acc: 0.6429\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.6529 Acc: 0.6522\n",
      "valid Loss: 0.6494 Acc: 0.6429\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.6506 Acc: 0.6739\n",
      "valid Loss: 0.6509 Acc: 0.6250\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.6400 Acc: 0.6581\n",
      "valid Loss: 0.6485 Acc: 0.6310\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.6442 Acc: 0.6621\n",
      "valid Loss: 0.6547 Acc: 0.6131\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.6484 Acc: 0.6502\n",
      "valid Loss: 0.6469 Acc: 0.6310\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.6359 Acc: 0.6798\n",
      "valid Loss: 0.6531 Acc: 0.6131\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.6447 Acc: 0.6561\n",
      "valid Loss: 0.6517 Acc: 0.6190\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "train Loss: 0.6484 Acc: 0.6423\n",
      "valid Loss: 0.6488 Acc: 0.6429\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "train Loss: 0.6398 Acc: 0.6680\n",
      "valid Loss: 0.6525 Acc: 0.6131\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "train Loss: 0.6473 Acc: 0.6601\n",
      "valid Loss: 0.6508 Acc: 0.6190\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "train Loss: 0.6457 Acc: 0.6581\n",
      "valid Loss: 0.6526 Acc: 0.6131\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "train Loss: 0.6429 Acc: 0.6601\n",
      "valid Loss: 0.6527 Acc: 0.6190\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "train Loss: 0.6366 Acc: 0.6542\n",
      "valid Loss: 0.6493 Acc: 0.6369\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "train Loss: 0.6580 Acc: 0.6502\n",
      "valid Loss: 0.6449 Acc: 0.6310\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "train Loss: 0.6431 Acc: 0.6581\n",
      "valid Loss: 0.6474 Acc: 0.6310\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "train Loss: 0.6463 Acc: 0.6542\n",
      "valid Loss: 0.6475 Acc: 0.6310\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "train Loss: 0.6424 Acc: 0.6660\n",
      "valid Loss: 0.6476 Acc: 0.6369\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "train Loss: 0.6572 Acc: 0.6561\n",
      "valid Loss: 0.6475 Acc: 0.6310\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "train Loss: 0.6429 Acc: 0.6640\n",
      "valid Loss: 0.6504 Acc: 0.6190\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "train Loss: 0.6420 Acc: 0.6621\n",
      "valid Loss: 0.6472 Acc: 0.6310\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "train Loss: 0.6463 Acc: 0.6640\n",
      "valid Loss: 0.6529 Acc: 0.6131\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "train Loss: 0.6392 Acc: 0.6581\n",
      "valid Loss: 0.6469 Acc: 0.6369\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "train Loss: 0.6516 Acc: 0.6640\n",
      "valid Loss: 0.6446 Acc: 0.6310\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "train Loss: 0.6433 Acc: 0.6601\n",
      "valid Loss: 0.6470 Acc: 0.6369\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "train Loss: 0.6465 Acc: 0.6680\n",
      "valid Loss: 0.6503 Acc: 0.6250\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "train Loss: 0.6442 Acc: 0.6719\n",
      "valid Loss: 0.6509 Acc: 0.6190\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.6581\n",
      "valid Loss: 0.6472 Acc: 0.6310\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "train Loss: 0.6393 Acc: 0.6621\n",
      "valid Loss: 0.6480 Acc: 0.6190\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "train Loss: 0.6494 Acc: 0.6443\n",
      "valid Loss: 0.6530 Acc: 0.6190\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "train Loss: 0.6471 Acc: 0.6561\n",
      "valid Loss: 0.6509 Acc: 0.6190\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "train Loss: 0.6369 Acc: 0.6779\n",
      "valid Loss: 0.6477 Acc: 0.6250\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "train Loss: 0.6512 Acc: 0.6482\n",
      "valid Loss: 0.6489 Acc: 0.6190\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "train Loss: 0.6464 Acc: 0.6700\n",
      "valid Loss: 0.6501 Acc: 0.6250\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "train Loss: 0.6371 Acc: 0.6581\n",
      "valid Loss: 0.6432 Acc: 0.6310\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "train Loss: 0.6417 Acc: 0.6561\n",
      "valid Loss: 0.6492 Acc: 0.6250\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "train Loss: 0.6410 Acc: 0.6719\n",
      "valid Loss: 0.6486 Acc: 0.6190\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "train Loss: 0.6373 Acc: 0.6522\n",
      "valid Loss: 0.6596 Acc: 0.6012\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "train Loss: 0.6467 Acc: 0.6522\n",
      "valid Loss: 0.6495 Acc: 0.6190\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "train Loss: 0.6481 Acc: 0.6462\n",
      "valid Loss: 0.6444 Acc: 0.6310\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "train Loss: 0.6335 Acc: 0.6522\n",
      "valid Loss: 0.6472 Acc: 0.6250\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "train Loss: 0.6384 Acc: 0.6798\n",
      "valid Loss: 0.6564 Acc: 0.6131\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "train Loss: 0.6384 Acc: 0.6601\n",
      "valid Loss: 0.6566 Acc: 0.6071\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "train Loss: 0.6356 Acc: 0.6581\n",
      "valid Loss: 0.6495 Acc: 0.6190\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "train Loss: 0.6388 Acc: 0.6700\n",
      "valid Loss: 0.6526 Acc: 0.6190\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "train Loss: 0.6399 Acc: 0.6462\n",
      "valid Loss: 0.6454 Acc: 0.6310\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "train Loss: 0.6511 Acc: 0.6621\n",
      "valid Loss: 0.6498 Acc: 0.6190\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "train Loss: 0.6421 Acc: 0.6660\n",
      "valid Loss: 0.6529 Acc: 0.6190\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "train Loss: 0.6337 Acc: 0.6640\n",
      "valid Loss: 0.6571 Acc: 0.6071\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "train Loss: 0.6458 Acc: 0.6344\n",
      "valid Loss: 0.6535 Acc: 0.6190\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "train Loss: 0.6362 Acc: 0.6640\n",
      "valid Loss: 0.6540 Acc: 0.6190\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "train Loss: 0.6377 Acc: 0.6700\n",
      "valid Loss: 0.6544 Acc: 0.6190\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "train Loss: 0.6329 Acc: 0.6522\n",
      "valid Loss: 0.6465 Acc: 0.6310\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "train Loss: 0.6368 Acc: 0.6621\n",
      "valid Loss: 0.6460 Acc: 0.6429\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "train Loss: 0.6455 Acc: 0.6522\n",
      "valid Loss: 0.6470 Acc: 0.6310\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "train Loss: 0.6295 Acc: 0.6700\n",
      "valid Loss: 0.6560 Acc: 0.6131\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "train Loss: 0.6417 Acc: 0.6482\n",
      "valid Loss: 0.6529 Acc: 0.6131\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "train Loss: 0.6392 Acc: 0.6719\n",
      "valid Loss: 0.6619 Acc: 0.6012\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "train Loss: 0.6454 Acc: 0.6542\n",
      "valid Loss: 0.6504 Acc: 0.6190\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "train Loss: 0.6416 Acc: 0.6640\n",
      "valid Loss: 0.6448 Acc: 0.6250\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "train Loss: 0.6352 Acc: 0.6462\n",
      "valid Loss: 0.6469 Acc: 0.6250\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "train Loss: 0.6409 Acc: 0.6621\n",
      "valid Loss: 0.6563 Acc: 0.6131\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "train Loss: 0.6356 Acc: 0.6601\n",
      "valid Loss: 0.6477 Acc: 0.6190\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "train Loss: 0.6354 Acc: 0.6542\n",
      "valid Loss: 0.6408 Acc: 0.6488\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "train Loss: 0.6314 Acc: 0.6640\n",
      "valid Loss: 0.6634 Acc: 0.6012\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "train Loss: 0.6428 Acc: 0.6482\n",
      "valid Loss: 0.6470 Acc: 0.6190\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "train Loss: 0.6307 Acc: 0.6601\n",
      "valid Loss: 0.6552 Acc: 0.6190\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "train Loss: 0.6409 Acc: 0.6561\n",
      "valid Loss: 0.6460 Acc: 0.6369\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "train Loss: 0.6422 Acc: 0.6640\n",
      "valid Loss: 0.6512 Acc: 0.6131\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "train Loss: 0.6324 Acc: 0.6640\n",
      "valid Loss: 0.6515 Acc: 0.6190\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "train Loss: 0.6390 Acc: 0.6462\n",
      "valid Loss: 0.6504 Acc: 0.6190\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "train Loss: 0.6360 Acc: 0.6719\n",
      "valid Loss: 0.6470 Acc: 0.6250\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "train Loss: 0.6394 Acc: 0.6522\n",
      "valid Loss: 0.6538 Acc: 0.6131\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "train Loss: 0.6258 Acc: 0.6482\n",
      "valid Loss: 0.6506 Acc: 0.6190\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "train Loss: 0.6296 Acc: 0.6502\n",
      "valid Loss: 0.6475 Acc: 0.6190\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "train Loss: 0.6415 Acc: 0.6561\n",
      "valid Loss: 0.6472 Acc: 0.6190\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "train Loss: 0.6359 Acc: 0.6759\n",
      "valid Loss: 0.6476 Acc: 0.6190\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "train Loss: 0.6369 Acc: 0.6522\n",
      "valid Loss: 0.6525 Acc: 0.6131\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "train Loss: 0.6377 Acc: 0.6680\n",
      "valid Loss: 0.6585 Acc: 0.5952\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "train Loss: 0.6451 Acc: 0.6522\n",
      "valid Loss: 0.6461 Acc: 0.6190\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "train Loss: 0.6350 Acc: 0.6581\n",
      "valid Loss: 0.6520 Acc: 0.6131\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "train Loss: 0.6253 Acc: 0.6660\n",
      "valid Loss: 0.6526 Acc: 0.6071\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n",
      "train Loss: 0.6298 Acc: 0.6581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.6499 Acc: 0.6131\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "train Loss: 0.6392 Acc: 0.6462\n",
      "valid Loss: 0.6400 Acc: 0.6310\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "train Loss: 0.6522 Acc: 0.6719\n",
      "valid Loss: 0.6850 Acc: 0.5833\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "train Loss: 0.6423 Acc: 0.6561\n",
      "valid Loss: 0.6475 Acc: 0.6250\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "train Loss: 0.6476 Acc: 0.6601\n",
      "valid Loss: 0.6630 Acc: 0.5952\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "train Loss: 0.6368 Acc: 0.6680\n",
      "valid Loss: 0.6474 Acc: 0.6250\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "train Loss: 0.6384 Acc: 0.6561\n",
      "valid Loss: 0.6484 Acc: 0.6190\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "train Loss: 0.6316 Acc: 0.6482\n",
      "valid Loss: 0.6500 Acc: 0.6131\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "train Loss: 0.6271 Acc: 0.6719\n",
      "valid Loss: 0.6505 Acc: 0.6131\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "train Loss: 0.6436 Acc: 0.6759\n",
      "valid Loss: 0.6493 Acc: 0.6071\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "train Loss: 0.6301 Acc: 0.6601\n",
      "valid Loss: 0.6455 Acc: 0.6310\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "train Loss: 0.6319 Acc: 0.6482\n",
      "valid Loss: 0.6469 Acc: 0.6250\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "train Loss: 0.6390 Acc: 0.6779\n",
      "valid Loss: 0.6487 Acc: 0.6190\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "train Loss: 0.6487 Acc: 0.6542\n",
      "valid Loss: 0.6521 Acc: 0.6131\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "train Loss: 0.6357 Acc: 0.6561\n",
      "valid Loss: 0.6504 Acc: 0.6190\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "train Loss: 0.6298 Acc: 0.6561\n",
      "valid Loss: 0.6487 Acc: 0.6190\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "train Loss: 0.6383 Acc: 0.6581\n",
      "valid Loss: 0.6479 Acc: 0.6190\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "train Loss: 0.6297 Acc: 0.6680\n",
      "valid Loss: 0.6485 Acc: 0.6190\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "train Loss: 0.6202 Acc: 0.6680\n",
      "valid Loss: 0.6481 Acc: 0.6190\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "train Loss: 0.6254 Acc: 0.6660\n",
      "valid Loss: 0.6483 Acc: 0.6190\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "train Loss: 0.6284 Acc: 0.6700\n",
      "valid Loss: 0.6484 Acc: 0.6190\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "train Loss: 0.6261 Acc: 0.6601\n",
      "valid Loss: 0.6487 Acc: 0.6131\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "train Loss: 0.6298 Acc: 0.6640\n",
      "valid Loss: 0.6491 Acc: 0.6131\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "train Loss: 0.6316 Acc: 0.6700\n",
      "valid Loss: 0.6490 Acc: 0.6131\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "train Loss: 0.6270 Acc: 0.6640\n",
      "valid Loss: 0.6484 Acc: 0.6131\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "train Loss: 0.6241 Acc: 0.6621\n",
      "valid Loss: 0.6489 Acc: 0.6131\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "train Loss: 0.6313 Acc: 0.6581\n",
      "valid Loss: 0.6496 Acc: 0.6131\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "train Loss: 0.6248 Acc: 0.6502\n",
      "valid Loss: 0.6478 Acc: 0.6190\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "train Loss: 0.6313 Acc: 0.6680\n",
      "valid Loss: 0.6483 Acc: 0.6131\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "train Loss: 0.6206 Acc: 0.6680\n",
      "valid Loss: 0.6473 Acc: 0.6190\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.6680\n",
      "valid Loss: 0.6472 Acc: 0.6190\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "train Loss: 0.6329 Acc: 0.6660\n",
      "valid Loss: 0.6482 Acc: 0.6131\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "train Loss: 0.6295 Acc: 0.6561\n",
      "valid Loss: 0.6490 Acc: 0.6131\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "train Loss: 0.6242 Acc: 0.6700\n",
      "valid Loss: 0.6491 Acc: 0.6131\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "train Loss: 0.6291 Acc: 0.6640\n",
      "valid Loss: 0.6485 Acc: 0.6131\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "train Loss: 0.6331 Acc: 0.6561\n",
      "valid Loss: 0.6491 Acc: 0.6131\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "train Loss: 0.6301 Acc: 0.6561\n",
      "valid Loss: 0.6492 Acc: 0.6131\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "train Loss: 0.6267 Acc: 0.6700\n",
      "valid Loss: 0.6497 Acc: 0.6131\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "train Loss: 0.6359 Acc: 0.6561\n",
      "valid Loss: 0.6481 Acc: 0.6131\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "train Loss: 0.6251 Acc: 0.6561\n",
      "valid Loss: 0.6488 Acc: 0.6131\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "train Loss: 0.6247 Acc: 0.6700\n",
      "valid Loss: 0.6479 Acc: 0.6131\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "train Loss: 0.6225 Acc: 0.6660\n",
      "valid Loss: 0.6479 Acc: 0.6131\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "train Loss: 0.6315 Acc: 0.6680\n",
      "valid Loss: 0.6485 Acc: 0.6131\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "train Loss: 0.6233 Acc: 0.6601\n",
      "valid Loss: 0.6478 Acc: 0.6131\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "train Loss: 0.6234 Acc: 0.6640\n",
      "valid Loss: 0.6473 Acc: 0.6190\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "train Loss: 0.6251 Acc: 0.6640\n",
      "valid Loss: 0.6481 Acc: 0.6131\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "train Loss: 0.6220 Acc: 0.6779\n",
      "valid Loss: 0.6478 Acc: 0.6131\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "train Loss: 0.6231 Acc: 0.6680\n",
      "valid Loss: 0.6461 Acc: 0.6190\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "train Loss: 0.6212 Acc: 0.6719\n",
      "valid Loss: 0.6473 Acc: 0.6190\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "train Loss: 0.6275 Acc: 0.6640\n",
      "valid Loss: 0.6471 Acc: 0.6190\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "train Loss: 0.6253 Acc: 0.6680\n",
      "valid Loss: 0.6477 Acc: 0.6190\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "train Loss: 0.6181 Acc: 0.6759\n",
      "valid Loss: 0.6489 Acc: 0.6131\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "train Loss: 0.6270 Acc: 0.6680\n",
      "valid Loss: 0.6492 Acc: 0.6131\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "train Loss: 0.6211 Acc: 0.6640\n",
      "valid Loss: 0.6480 Acc: 0.6131\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "train Loss: 0.6240 Acc: 0.6660\n",
      "valid Loss: 0.6488 Acc: 0.6131\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "train Loss: 0.6253 Acc: 0.6660\n",
      "valid Loss: 0.6471 Acc: 0.6190\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "train Loss: 0.6274 Acc: 0.6621\n",
      "valid Loss: 0.6486 Acc: 0.6131\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "train Loss: 0.6251 Acc: 0.6601\n",
      "valid Loss: 0.6484 Acc: 0.6131\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "train Loss: 0.6221 Acc: 0.6621\n",
      "valid Loss: 0.6473 Acc: 0.6131\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "train Loss: 0.6278 Acc: 0.6561\n",
      "valid Loss: 0.6485 Acc: 0.6131\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "train Loss: 0.6218 Acc: 0.6601\n",
      "valid Loss: 0.6488 Acc: 0.6131\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "train Loss: 0.6180 Acc: 0.6621\n",
      "valid Loss: 0.6480 Acc: 0.6131\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "train Loss: 0.6262 Acc: 0.6601\n",
      "valid Loss: 0.6467 Acc: 0.6190\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "train Loss: 0.6353 Acc: 0.6542\n",
      "valid Loss: 0.6478 Acc: 0.6131\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "train Loss: 0.6245 Acc: 0.6660\n",
      "valid Loss: 0.6482 Acc: 0.6131\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "train Loss: 0.6221 Acc: 0.6660\n",
      "valid Loss: 0.6483 Acc: 0.6131\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "train Loss: 0.6320 Acc: 0.6640\n",
      "valid Loss: 0.6467 Acc: 0.6190\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "train Loss: 0.6229 Acc: 0.6700\n",
      "valid Loss: 0.6475 Acc: 0.6131\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "train Loss: 0.6114 Acc: 0.6719\n",
      "valid Loss: 0.6468 Acc: 0.6190\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "train Loss: 0.6194 Acc: 0.6581\n",
      "valid Loss: 0.6462 Acc: 0.6190\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "train Loss: 0.6228 Acc: 0.6739\n",
      "valid Loss: 0.6471 Acc: 0.6131\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "train Loss: 0.6165 Acc: 0.6719\n",
      "valid Loss: 0.6477 Acc: 0.6131\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "train Loss: 0.6240 Acc: 0.6561\n",
      "valid Loss: 0.6464 Acc: 0.6190\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "train Loss: 0.6205 Acc: 0.6700\n",
      "valid Loss: 0.6464 Acc: 0.6190\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "train Loss: 0.6169 Acc: 0.6660\n",
      "valid Loss: 0.6461 Acc: 0.6190\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "train Loss: 0.6236 Acc: 0.6621\n",
      "valid Loss: 0.6462 Acc: 0.6131\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "train Loss: 0.6179 Acc: 0.6660\n",
      "valid Loss: 0.6462 Acc: 0.6131\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "train Loss: 0.6242 Acc: 0.6640\n",
      "valid Loss: 0.6475 Acc: 0.6131\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "train Loss: 0.6212 Acc: 0.6739\n",
      "valid Loss: 0.6462 Acc: 0.6131\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "train Loss: 0.6223 Acc: 0.6660\n",
      "valid Loss: 0.6466 Acc: 0.6131\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "train Loss: 0.6250 Acc: 0.6601\n",
      "valid Loss: 0.6476 Acc: 0.6071\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "train Loss: 0.6319 Acc: 0.6542\n",
      "valid Loss: 0.6477 Acc: 0.6071\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "train Loss: 0.6222 Acc: 0.6700\n",
      "valid Loss: 0.6466 Acc: 0.6131\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "train Loss: 0.6239 Acc: 0.6759\n",
      "valid Loss: 0.6465 Acc: 0.6131\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "train Loss: 0.6265 Acc: 0.6542\n",
      "valid Loss: 0.6468 Acc: 0.6131\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "train Loss: 0.6325 Acc: 0.6443\n",
      "valid Loss: 0.6477 Acc: 0.6071\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "train Loss: 0.6122 Acc: 0.6719\n",
      "valid Loss: 0.6454 Acc: 0.6190\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "train Loss: 0.6232 Acc: 0.6700\n",
      "valid Loss: 0.6476 Acc: 0.6131\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "train Loss: 0.6200 Acc: 0.6581\n",
      "valid Loss: 0.6464 Acc: 0.6131\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "train Loss: 0.6131 Acc: 0.6700\n",
      "valid Loss: 0.6459 Acc: 0.6190\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "train Loss: 0.6270 Acc: 0.6640\n",
      "valid Loss: 0.6463 Acc: 0.6131\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "train Loss: 0.6257 Acc: 0.6680\n",
      "valid Loss: 0.6465 Acc: 0.6131\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "train Loss: 0.6228 Acc: 0.6719\n",
      "valid Loss: 0.6461 Acc: 0.6131\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n",
      "train Loss: 0.6289 Acc: 0.6680\n",
      "valid Loss: 0.6456 Acc: 0.6131\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6266 Acc: 0.6739\n",
      "valid Loss: 0.6459 Acc: 0.6131\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "train Loss: 0.6270 Acc: 0.6640\n",
      "valid Loss: 0.6454 Acc: 0.6131\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "train Loss: 0.6214 Acc: 0.6838\n",
      "valid Loss: 0.6451 Acc: 0.6131\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "train Loss: 0.6218 Acc: 0.6601\n",
      "valid Loss: 0.6467 Acc: 0.6071\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "train Loss: 0.6234 Acc: 0.6621\n",
      "valid Loss: 0.6448 Acc: 0.6190\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "train Loss: 0.6180 Acc: 0.6601\n",
      "valid Loss: 0.6457 Acc: 0.6131\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "train Loss: 0.6192 Acc: 0.6798\n",
      "valid Loss: 0.6460 Acc: 0.6071\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "train Loss: 0.6195 Acc: 0.6700\n",
      "valid Loss: 0.6454 Acc: 0.6131\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "train Loss: 0.6174 Acc: 0.6660\n",
      "valid Loss: 0.6450 Acc: 0.6131\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "train Loss: 0.6227 Acc: 0.6680\n",
      "valid Loss: 0.6437 Acc: 0.6190\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "train Loss: 0.6191 Acc: 0.6640\n",
      "valid Loss: 0.6458 Acc: 0.6071\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "train Loss: 0.6226 Acc: 0.6581\n",
      "valid Loss: 0.6447 Acc: 0.6131\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "train Loss: 0.6294 Acc: 0.6621\n",
      "valid Loss: 0.6442 Acc: 0.6131\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "train Loss: 0.6257 Acc: 0.6601\n",
      "valid Loss: 0.6447 Acc: 0.6131\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "train Loss: 0.6319 Acc: 0.6640\n",
      "valid Loss: 0.6428 Acc: 0.6190\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "train Loss: 0.6254 Acc: 0.6700\n",
      "valid Loss: 0.6430 Acc: 0.6131\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "train Loss: 0.6176 Acc: 0.6522\n",
      "valid Loss: 0.6441 Acc: 0.6131\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "train Loss: 0.6232 Acc: 0.6542\n",
      "valid Loss: 0.6444 Acc: 0.6071\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "train Loss: 0.6196 Acc: 0.6621\n",
      "valid Loss: 0.6442 Acc: 0.6131\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "train Loss: 0.6151 Acc: 0.6759\n",
      "valid Loss: 0.6415 Acc: 0.6190\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "train Loss: 0.6129 Acc: 0.6798\n",
      "valid Loss: 0.6420 Acc: 0.6190\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "train Loss: 0.6315 Acc: 0.6601\n",
      "valid Loss: 0.6421 Acc: 0.6190\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "train Loss: 0.6211 Acc: 0.6739\n",
      "valid Loss: 0.6421 Acc: 0.6190\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "train Loss: 0.6158 Acc: 0.6719\n",
      "valid Loss: 0.6422 Acc: 0.6190\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "train Loss: 0.6267 Acc: 0.6621\n",
      "valid Loss: 0.6423 Acc: 0.6190\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "train Loss: 0.6236 Acc: 0.6660\n",
      "valid Loss: 0.6423 Acc: 0.6190\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "train Loss: 0.6281 Acc: 0.6561\n",
      "valid Loss: 0.6424 Acc: 0.6190\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "train Loss: 0.6179 Acc: 0.6660\n",
      "valid Loss: 0.6427 Acc: 0.6131\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "train Loss: 0.6124 Acc: 0.6739\n",
      "valid Loss: 0.6429 Acc: 0.6131\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "train Loss: 0.6152 Acc: 0.6700\n",
      "valid Loss: 0.6428 Acc: 0.6131\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "train Loss: 0.6051 Acc: 0.6877\n",
      "valid Loss: 0.6430 Acc: 0.6131\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "train Loss: 0.6293 Acc: 0.6660\n",
      "valid Loss: 0.6431 Acc: 0.6131\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "train Loss: 0.6199 Acc: 0.6719\n",
      "valid Loss: 0.6431 Acc: 0.6131\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "train Loss: 0.6191 Acc: 0.6759\n",
      "valid Loss: 0.6432 Acc: 0.6131\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "train Loss: 0.6156 Acc: 0.6759\n",
      "valid Loss: 0.6431 Acc: 0.6131\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "train Loss: 0.6215 Acc: 0.6700\n",
      "valid Loss: 0.6434 Acc: 0.6131\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "train Loss: 0.6228 Acc: 0.6700\n",
      "valid Loss: 0.6433 Acc: 0.6131\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "train Loss: 0.6215 Acc: 0.6640\n",
      "valid Loss: 0.6435 Acc: 0.6131\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "train Loss: 0.6118 Acc: 0.6798\n",
      "valid Loss: 0.6433 Acc: 0.6131\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "train Loss: 0.6147 Acc: 0.6700\n",
      "valid Loss: 0.6434 Acc: 0.6131\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "train Loss: 0.6132 Acc: 0.6719\n",
      "valid Loss: 0.6434 Acc: 0.6131\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "train Loss: 0.6126 Acc: 0.6779\n",
      "valid Loss: 0.6433 Acc: 0.6131\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "train Loss: 0.6107 Acc: 0.6700\n",
      "valid Loss: 0.6433 Acc: 0.6131\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "train Loss: 0.6161 Acc: 0.6680\n",
      "valid Loss: 0.6433 Acc: 0.6131\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "train Loss: 0.6170 Acc: 0.6838\n",
      "valid Loss: 0.6434 Acc: 0.6131\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "train Loss: 0.6144 Acc: 0.6680\n",
      "valid Loss: 0.6431 Acc: 0.6131\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "train Loss: 0.6188 Acc: 0.6660\n",
      "valid Loss: 0.6431 Acc: 0.6131\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "train Loss: 0.6171 Acc: 0.6640\n",
      "valid Loss: 0.6433 Acc: 0.6131\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "train Loss: 0.6167 Acc: 0.6640\n",
      "valid Loss: 0.6432 Acc: 0.6131\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "train Loss: 0.6223 Acc: 0.6700\n",
      "valid Loss: 0.6433 Acc: 0.6131\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "train Loss: 0.6158 Acc: 0.6561\n",
      "valid Loss: 0.6434 Acc: 0.6131\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "train Loss: 0.6114 Acc: 0.6719\n",
      "valid Loss: 0.6433 Acc: 0.6131\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "train Loss: 0.6088 Acc: 0.6621\n",
      "valid Loss: 0.6431 Acc: 0.6131\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "train Loss: 0.6220 Acc: 0.6700\n",
      "valid Loss: 0.6432 Acc: 0.6131\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "train Loss: 0.6223 Acc: 0.6660\n",
      "valid Loss: 0.6432 Acc: 0.6131\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "train Loss: 0.6167 Acc: 0.6779\n",
      "valid Loss: 0.6432 Acc: 0.6131\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "train Loss: 0.6249 Acc: 0.6581\n",
      "valid Loss: 0.6433 Acc: 0.6131\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "train Loss: 0.6169 Acc: 0.6640\n",
      "valid Loss: 0.6432 Acc: 0.6131\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "train Loss: 0.6174 Acc: 0.6779\n",
      "valid Loss: 0.6432 Acc: 0.6131\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "train Loss: 0.6180 Acc: 0.6660\n",
      "valid Loss: 0.6432 Acc: 0.6131\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "train Loss: 0.6161 Acc: 0.6700\n",
      "valid Loss: 0.6433 Acc: 0.6131\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "train Loss: 0.6234 Acc: 0.6621\n",
      "valid Loss: 0.6433 Acc: 0.6131\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "train Loss: 0.6182 Acc: 0.6601\n",
      "valid Loss: 0.6435 Acc: 0.6131\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "train Loss: 0.6264 Acc: 0.6640\n",
      "valid Loss: 0.6432 Acc: 0.6131\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "train Loss: 0.6175 Acc: 0.6759\n",
      "valid Loss: 0.6433 Acc: 0.6131\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "train Loss: 0.6251 Acc: 0.6621\n",
      "valid Loss: 0.6433 Acc: 0.6131\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "train Loss: 0.6199 Acc: 0.6719\n",
      "valid Loss: 0.6431 Acc: 0.6131\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "train Loss: 0.6161 Acc: 0.6739\n",
      "valid Loss: 0.6430 Acc: 0.6131\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "train Loss: 0.6093 Acc: 0.6759\n",
      "valid Loss: 0.6427 Acc: 0.6131\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "train Loss: 0.6173 Acc: 0.6719\n",
      "valid Loss: 0.6428 Acc: 0.6131\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "train Loss: 0.6173 Acc: 0.6719\n",
      "valid Loss: 0.6428 Acc: 0.6131\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "train Loss: 0.6122 Acc: 0.6838\n",
      "valid Loss: 0.6428 Acc: 0.6131\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "train Loss: 0.6141 Acc: 0.6621\n",
      "valid Loss: 0.6429 Acc: 0.6131\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "train Loss: 0.6233 Acc: 0.6621\n",
      "valid Loss: 0.6427 Acc: 0.6131\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "train Loss: 0.6270 Acc: 0.6660\n",
      "valid Loss: 0.6429 Acc: 0.6131\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "train Loss: 0.6243 Acc: 0.6779\n",
      "valid Loss: 0.6428 Acc: 0.6131\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "train Loss: 0.6209 Acc: 0.6561\n",
      "valid Loss: 0.6427 Acc: 0.6131\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "train Loss: 0.6102 Acc: 0.6798\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "train Loss: 0.6189 Acc: 0.6818\n",
      "valid Loss: 0.6427 Acc: 0.6131\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "train Loss: 0.6076 Acc: 0.6739\n",
      "valid Loss: 0.6427 Acc: 0.6131\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "train Loss: 0.6174 Acc: 0.6700\n",
      "valid Loss: 0.6428 Acc: 0.6131\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "train Loss: 0.6146 Acc: 0.6621\n",
      "valid Loss: 0.6427 Acc: 0.6131\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "train Loss: 0.6221 Acc: 0.6621\n",
      "valid Loss: 0.6427 Acc: 0.6131\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "train Loss: 0.6269 Acc: 0.6621\n",
      "valid Loss: 0.6427 Acc: 0.6131\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "train Loss: 0.6158 Acc: 0.6700\n",
      "valid Loss: 0.6428 Acc: 0.6131\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "train Loss: 0.6210 Acc: 0.6660\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "train Loss: 0.6123 Acc: 0.6739\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "train Loss: 0.6099 Acc: 0.6877\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "train Loss: 0.6201 Acc: 0.6621\n",
      "valid Loss: 0.6427 Acc: 0.6131\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "train Loss: 0.6126 Acc: 0.6818\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "train Loss: 0.6318 Acc: 0.6542\n",
      "valid Loss: 0.6427 Acc: 0.6131\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "train Loss: 0.6239 Acc: 0.6640\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n",
      "train Loss: 0.6116 Acc: 0.6700\n",
      "valid Loss: 0.6427 Acc: 0.6131\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "train Loss: 0.6240 Acc: 0.6601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "train Loss: 0.6184 Acc: 0.6660\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "train Loss: 0.6138 Acc: 0.6739\n",
      "valid Loss: 0.6427 Acc: 0.6131\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "train Loss: 0.6167 Acc: 0.6680\n",
      "valid Loss: 0.6423 Acc: 0.6131\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "train Loss: 0.6172 Acc: 0.6798\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "train Loss: 0.6225 Acc: 0.6542\n",
      "valid Loss: 0.6423 Acc: 0.6131\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "train Loss: 0.6169 Acc: 0.6779\n",
      "valid Loss: 0.6424 Acc: 0.6131\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "train Loss: 0.6234 Acc: 0.6680\n",
      "valid Loss: 0.6423 Acc: 0.6131\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "train Loss: 0.6175 Acc: 0.6680\n",
      "valid Loss: 0.6423 Acc: 0.6131\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "train Loss: 0.6163 Acc: 0.6739\n",
      "valid Loss: 0.6423 Acc: 0.6131\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "train Loss: 0.6190 Acc: 0.6660\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "train Loss: 0.6228 Acc: 0.6660\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "train Loss: 0.6168 Acc: 0.6719\n",
      "valid Loss: 0.6427 Acc: 0.6131\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "train Loss: 0.6066 Acc: 0.6640\n",
      "valid Loss: 0.6428 Acc: 0.6131\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "train Loss: 0.6161 Acc: 0.6680\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "train Loss: 0.6190 Acc: 0.6680\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "train Loss: 0.6234 Acc: 0.6719\n",
      "valid Loss: 0.6423 Acc: 0.6131\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "train Loss: 0.6206 Acc: 0.6640\n",
      "valid Loss: 0.6423 Acc: 0.6131\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "train Loss: 0.6210 Acc: 0.6680\n",
      "valid Loss: 0.6427 Acc: 0.6131\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "train Loss: 0.6183 Acc: 0.6739\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "train Loss: 0.6182 Acc: 0.6640\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "train Loss: 0.6102 Acc: 0.6719\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "train Loss: 0.6147 Acc: 0.6759\n",
      "valid Loss: 0.6423 Acc: 0.6131\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "train Loss: 0.6234 Acc: 0.6719\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "train Loss: 0.6118 Acc: 0.6798\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "train Loss: 0.6169 Acc: 0.6719\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "train Loss: 0.6152 Acc: 0.6759\n",
      "valid Loss: 0.6424 Acc: 0.6131\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "train Loss: 0.6241 Acc: 0.6601\n",
      "valid Loss: 0.6424 Acc: 0.6131\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "train Loss: 0.6261 Acc: 0.6640\n",
      "valid Loss: 0.6424 Acc: 0.6131\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "train Loss: 0.6193 Acc: 0.6640\n",
      "valid Loss: 0.6424 Acc: 0.6131\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "train Loss: 0.6264 Acc: 0.6640\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "train Loss: 0.6140 Acc: 0.6660\n",
      "valid Loss: 0.6424 Acc: 0.6131\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "train Loss: 0.6257 Acc: 0.6719\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "train Loss: 0.6097 Acc: 0.6660\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "train Loss: 0.6281 Acc: 0.6660\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "train Loss: 0.6234 Acc: 0.6621\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "train Loss: 0.6210 Acc: 0.6561\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "train Loss: 0.6090 Acc: 0.6779\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "train Loss: 0.6265 Acc: 0.6680\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "train Loss: 0.6168 Acc: 0.6700\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "train Loss: 0.6194 Acc: 0.6660\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "train Loss: 0.6299 Acc: 0.6700\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "train Loss: 0.6256 Acc: 0.6660\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "train Loss: 0.6152 Acc: 0.6818\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "train Loss: 0.6154 Acc: 0.6700\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "train Loss: 0.6221 Acc: 0.6522\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "train Loss: 0.6275 Acc: 0.6660\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "train Loss: 0.6198 Acc: 0.6759\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "train Loss: 0.6203 Acc: 0.6798\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "train Loss: 0.6235 Acc: 0.6798\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "train Loss: 0.6241 Acc: 0.6601\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "train Loss: 0.6196 Acc: 0.6719\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "train Loss: 0.6221 Acc: 0.6621\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "train Loss: 0.6161 Acc: 0.6779\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "train Loss: 0.6237 Acc: 0.6601\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "train Loss: 0.6215 Acc: 0.6601\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "train Loss: 0.6193 Acc: 0.6818\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "train Loss: 0.6164 Acc: 0.6759\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "train Loss: 0.6103 Acc: 0.6719\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "train Loss: 0.6125 Acc: 0.6838\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "train Loss: 0.6128 Acc: 0.6700\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "train Loss: 0.6006 Acc: 0.6700\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "train Loss: 0.6199 Acc: 0.6601\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "train Loss: 0.6267 Acc: 0.6680\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "train Loss: 0.6237 Acc: 0.6621\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "train Loss: 0.6166 Acc: 0.6621\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "train Loss: 0.6126 Acc: 0.6660\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "train Loss: 0.6182 Acc: 0.6700\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "train Loss: 0.6165 Acc: 0.6680\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "train Loss: 0.6158 Acc: 0.6700\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "train Loss: 0.6172 Acc: 0.6739\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "train Loss: 0.6252 Acc: 0.6759\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "train Loss: 0.6144 Acc: 0.6798\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "train Loss: 0.6176 Acc: 0.6700\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "train Loss: 0.6223 Acc: 0.6798\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "train Loss: 0.6246 Acc: 0.6759\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "train Loss: 0.6229 Acc: 0.6660\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "train Loss: 0.6134 Acc: 0.6700\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "train Loss: 0.6093 Acc: 0.6640\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "train Loss: 0.6251 Acc: 0.6621\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "train Loss: 0.6204 Acc: 0.6700\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "train Loss: 0.6142 Acc: 0.6680\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "train Loss: 0.6207 Acc: 0.6700\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "train Loss: 0.6286 Acc: 0.6680\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "train Loss: 0.6155 Acc: 0.6680\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "train Loss: 0.6184 Acc: 0.6719\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "train Loss: 0.6094 Acc: 0.6917\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "train Loss: 0.6292 Acc: 0.6561\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "train Loss: 0.6114 Acc: 0.6798\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "train Loss: 0.6195 Acc: 0.6739\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "train Loss: 0.6163 Acc: 0.6640\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "train Loss: 0.6229 Acc: 0.6719\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n",
      "train Loss: 0.6156 Acc: 0.6739\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "train Loss: 0.6247 Acc: 0.6640\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6230 Acc: 0.6660\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "train Loss: 0.6188 Acc: 0.6779\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "train Loss: 0.6271 Acc: 0.6660\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "train Loss: 0.6205 Acc: 0.6719\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "train Loss: 0.6179 Acc: 0.6719\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "train Loss: 0.6197 Acc: 0.6621\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "train Loss: 0.6221 Acc: 0.6660\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "train Loss: 0.6272 Acc: 0.6700\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "train Loss: 0.6200 Acc: 0.6739\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "train Loss: 0.6168 Acc: 0.6542\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "train Loss: 0.6125 Acc: 0.6660\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "train Loss: 0.6145 Acc: 0.6660\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "train Loss: 0.6162 Acc: 0.6739\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "train Loss: 0.6229 Acc: 0.6640\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "train Loss: 0.6252 Acc: 0.6680\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "train Loss: 0.6136 Acc: 0.6719\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "train Loss: 0.6164 Acc: 0.6640\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "train Loss: 0.6147 Acc: 0.6798\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "train Loss: 0.6276 Acc: 0.6680\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "train Loss: 0.6195 Acc: 0.6680\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "train Loss: 0.6216 Acc: 0.6680\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "train Loss: 0.6269 Acc: 0.6660\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "train Loss: 0.6220 Acc: 0.6621\n",
      "valid Loss: 0.6426 Acc: 0.6131\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "train Loss: 0.6219 Acc: 0.6700\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "train Loss: 0.6125 Acc: 0.6739\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "train Loss: 0.6161 Acc: 0.6759\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "train Loss: 0.6159 Acc: 0.6719\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "train Loss: 0.6295 Acc: 0.6403\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "train Loss: 0.6108 Acc: 0.6680\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "train Loss: 0.6187 Acc: 0.6601\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "train Loss: 0.6139 Acc: 0.6779\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "train Loss: 0.6084 Acc: 0.6719\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "train Loss: 0.6194 Acc: 0.6759\n",
      "valid Loss: 0.6425 Acc: 0.6131\n",
      "\n",
      "Training complete in 593m 2s\n",
      "Best val Acc: 0.714286\n",
      "Total memory   :\t 25769803776\n",
      "Allocated memory   :\t 4623300608\n",
      "Free memory   :\t\t 21146503168\n",
      "Training model: 5 of 7\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.6714 Acc: 0.6364\n",
      "valid Loss: 0.7052 Acc: 0.3274\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.6702 Acc: 0.6304\n",
      "valid Loss: 0.6526 Acc: 0.6667\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.6501 Acc: 0.6522\n",
      "valid Loss: 1.4426 Acc: 0.6726\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.6447 Acc: 0.6245\n",
      "valid Loss: 2.2201 Acc: 0.6726\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.6259 Acc: 0.6542\n",
      "valid Loss: 0.6780 Acc: 0.6607\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.6459 Acc: 0.6285\n",
      "valid Loss: 1.5920 Acc: 0.3274\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.6195 Acc: 0.6700\n",
      "valid Loss: 0.8301 Acc: 0.6726\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.6076 Acc: 0.6621\n",
      "valid Loss: 5.5822 Acc: 0.3274\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.6529 Acc: 0.6462\n",
      "valid Loss: 1.2613 Acc: 0.6726\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.6129 Acc: 0.6700\n",
      "valid Loss: 0.8711 Acc: 0.5060\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.6240 Acc: 0.6798\n",
      "valid Loss: 4.2388 Acc: 0.3274\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.6193 Acc: 0.6779\n",
      "valid Loss: 0.6216 Acc: 0.7024\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.6132 Acc: 0.6798\n",
      "valid Loss: 1.2187 Acc: 0.3274\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.6201 Acc: 0.6937\n",
      "valid Loss: 0.9518 Acc: 0.4643\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.6300 Acc: 0.6581\n",
      "valid Loss: 0.7230 Acc: 0.6607\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.6076 Acc: 0.6937\n",
      "valid Loss: 0.6771 Acc: 0.6488\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.6207 Acc: 0.6680\n",
      "valid Loss: 0.6797 Acc: 0.6607\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.5995 Acc: 0.6858\n",
      "valid Loss: 1.1212 Acc: 0.6726\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.6030 Acc: 0.6739\n",
      "valid Loss: 4.9169 Acc: 0.3274\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.5653 Acc: 0.7016\n",
      "valid Loss: 3.0192 Acc: 0.3274\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.5844 Acc: 0.7036\n",
      "valid Loss: 1.8399 Acc: 0.6726\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.5518 Acc: 0.7253\n",
      "valid Loss: 3.8928 Acc: 0.6726\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.5654 Acc: 0.7036\n",
      "valid Loss: 3.4375 Acc: 0.3274\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.5423 Acc: 0.7451\n",
      "valid Loss: 2.7164 Acc: 0.6726\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.5548 Acc: 0.7194\n",
      "valid Loss: 2.9262 Acc: 0.3274\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.5106 Acc: 0.7332\n",
      "valid Loss: 3.4754 Acc: 0.3274\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.4565 Acc: 0.7727\n",
      "valid Loss: 0.7213 Acc: 0.7143\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.4382 Acc: 0.8043\n",
      "valid Loss: 0.7138 Acc: 0.6369\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.3761 Acc: 0.8538\n",
      "valid Loss: 7.4363 Acc: 0.3274\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.3272 Acc: 0.8597\n",
      "valid Loss: 7.8635 Acc: 0.6726\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.3555 Acc: 0.8439\n",
      "valid Loss: 2.0404 Acc: 0.3631\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.2241 Acc: 0.9111\n",
      "valid Loss: 0.9514 Acc: 0.6190\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.1761 Acc: 0.9328\n",
      "valid Loss: 1.3186 Acc: 0.5833\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.1792 Acc: 0.9308\n",
      "valid Loss: 1.4603 Acc: 0.4881\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.2147 Acc: 0.9091\n",
      "valid Loss: 3.1118 Acc: 0.6667\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.1257 Acc: 0.9585\n",
      "valid Loss: 1.4123 Acc: 0.5595\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.1660 Acc: 0.9368\n",
      "valid Loss: 1.2144 Acc: 0.6250\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.1154 Acc: 0.9526\n",
      "valid Loss: 1.2452 Acc: 0.6369\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.1004 Acc: 0.9723\n",
      "valid Loss: 2.0986 Acc: 0.6607\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.1318 Acc: 0.9585\n",
      "valid Loss: 1.4220 Acc: 0.6012\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.1420 Acc: 0.9506\n",
      "valid Loss: 5.0444 Acc: 0.6726\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.0856 Acc: 0.9704\n",
      "valid Loss: 2.0432 Acc: 0.4821\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.0897 Acc: 0.9723\n",
      "valid Loss: 5.0487 Acc: 0.3333\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.1117 Acc: 0.9684\n",
      "valid Loss: 5.4227 Acc: 0.6726\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.0979 Acc: 0.9605\n",
      "valid Loss: 4.8332 Acc: 0.6607\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.0663 Acc: 0.9842\n",
      "valid Loss: 4.8086 Acc: 0.3274\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.0713 Acc: 0.9704\n",
      "valid Loss: 6.3257 Acc: 0.6726\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.0928 Acc: 0.9783\n",
      "valid Loss: 7.5729 Acc: 0.6726\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.0957 Acc: 0.9545\n",
      "valid Loss: 1.9299 Acc: 0.6071\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.1331 Acc: 0.9526\n",
      "valid Loss: 10.1553 Acc: 0.6726\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.1200 Acc: 0.9526\n",
      "valid Loss: 6.0739 Acc: 0.6726\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.0964 Acc: 0.9644\n",
      "valid Loss: 7.8300 Acc: 0.3274\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.0315 Acc: 0.9921\n",
      "valid Loss: 2.1732 Acc: 0.5357\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.0339 Acc: 0.9881\n",
      "valid Loss: 2.6043 Acc: 0.5179\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.0660 Acc: 0.9763\n",
      "valid Loss: 1.6053 Acc: 0.6667\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.0865 Acc: 0.9704\n",
      "valid Loss: 2.0829 Acc: 0.4881\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.0519 Acc: 0.9862\n",
      "valid Loss: 9.5293 Acc: 0.3274\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.0602 Acc: 0.9783\n",
      "valid Loss: 1.6342 Acc: 0.6369\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.0992 Acc: 0.9684\n",
      "valid Loss: 5.1055 Acc: 0.6726\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0606 Acc: 0.9802\n",
      "valid Loss: 7.6941 Acc: 0.6726\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.0559 Acc: 0.9802\n",
      "valid Loss: 2.9518 Acc: 0.6607\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.1058 Acc: 0.9723\n",
      "valid Loss: 11.4237 Acc: 0.6726\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.0928 Acc: 0.9684\n",
      "valid Loss: 5.3903 Acc: 0.3393\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.0371 Acc: 0.9881\n",
      "valid Loss: 3.9627 Acc: 0.3810\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.0445 Acc: 0.9862\n",
      "valid Loss: 3.4554 Acc: 0.6607\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.0978 Acc: 0.9684\n",
      "valid Loss: 1.8172 Acc: 0.6131\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.0568 Acc: 0.9802\n",
      "valid Loss: 2.4043 Acc: 0.4762\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.0326 Acc: 0.9921\n",
      "valid Loss: 3.3192 Acc: 0.6548\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.0578 Acc: 0.9822\n",
      "valid Loss: 5.0976 Acc: 0.6667\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.0240 Acc: 0.9941\n",
      "valid Loss: 2.0146 Acc: 0.6071\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.0128 Acc: 0.9980\n",
      "valid Loss: 1.9242 Acc: 0.6310\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.0110 Acc: 0.9980\n",
      "valid Loss: 1.9805 Acc: 0.5893\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.0167 Acc: 0.9980\n",
      "valid Loss: 1.9991 Acc: 0.6429\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.0174 Acc: 0.9960\n",
      "valid Loss: 2.1302 Acc: 0.6131\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.0125 Acc: 0.9980\n",
      "valid Loss: 2.2767 Acc: 0.6071\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.0491 Acc: 0.9862\n",
      "valid Loss: 3.9092 Acc: 0.6786\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.0341 Acc: 0.9881\n",
      "valid Loss: 3.4483 Acc: 0.6548\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.0794 Acc: 0.9743\n",
      "valid Loss: 9.0737 Acc: 0.3274\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.0492 Acc: 0.9822\n",
      "valid Loss: 9.1082 Acc: 0.6726\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.0714 Acc: 0.9763\n",
      "valid Loss: 3.1258 Acc: 0.4167\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.0706 Acc: 0.9723\n",
      "valid Loss: 19.0890 Acc: 0.6726\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.0807 Acc: 0.9664\n",
      "valid Loss: 13.0660 Acc: 0.6726\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.0946 Acc: 0.9723\n",
      "valid Loss: 1.4817 Acc: 0.6012\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.0442 Acc: 0.9862\n",
      "valid Loss: 2.3049 Acc: 0.5595\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.0655 Acc: 0.9763\n",
      "valid Loss: 1.8087 Acc: 0.5655\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.0542 Acc: 0.9802\n",
      "valid Loss: 19.7511 Acc: 0.6726\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.1119 Acc: 0.9644\n",
      "valid Loss: 49.0686 Acc: 0.3274\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.1408 Acc: 0.9427\n",
      "valid Loss: 17.0824 Acc: 0.3274\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.1409 Acc: 0.9486\n",
      "valid Loss: 50.5812 Acc: 0.6726\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.1193 Acc: 0.9625\n",
      "valid Loss: 12.0314 Acc: 0.6726\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.0885 Acc: 0.9684\n",
      "valid Loss: 6.1982 Acc: 0.6726\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.0320 Acc: 0.9862\n",
      "valid Loss: 4.4648 Acc: 0.6786\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.0428 Acc: 0.9842\n",
      "valid Loss: 2.2035 Acc: 0.6429\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n",
      "train Loss: 0.0469 Acc: 0.9822\n",
      "valid Loss: 32.9497 Acc: 0.6726\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.1135 Acc: 0.9605\n",
      "valid Loss: 49.8409 Acc: 0.6726\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.0597 Acc: 0.9802\n",
      "valid Loss: 46.1318 Acc: 0.6726\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.0542 Acc: 0.9862\n",
      "valid Loss: 6.3597 Acc: 0.6726\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.0275 Acc: 0.9921\n",
      "valid Loss: 7.1953 Acc: 0.3333\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.0244 Acc: 0.9901\n",
      "valid Loss: 9.5259 Acc: 0.3214\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.0261 Acc: 0.9901\n",
      "valid Loss: 2.0954 Acc: 0.6429\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.0361 Acc: 0.9842\n",
      "valid Loss: 2.4507 Acc: 0.5833\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.0159 Acc: 0.9941\n",
      "valid Loss: 2.1016 Acc: 0.6071\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.0062 Acc: 1.0000\n",
      "valid Loss: 2.1337 Acc: 0.6131\n",
      "Early stopping\n",
      "Training complete in 41m 22s\n",
      "Best val Acc: 0.714286\n",
      "Total memory   :\t 25769803776\n",
      "Allocated memory   :\t 920558080\n",
      "Free memory   :\t\t 24849245696\n",
      "Training model: 6 of 7\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.7144 Acc: 0.5198\n",
      "valid Loss: 0.6471 Acc: 0.6905\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.7247 Acc: 0.5909\n",
      "valid Loss: 0.6585 Acc: 0.6607\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.6835 Acc: 0.6462\n",
      "valid Loss: 0.6195 Acc: 0.7143\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.6283 Acc: 0.6561\n",
      "valid Loss: 0.6069 Acc: 0.6905\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.5230 Acc: 0.7431\n",
      "valid Loss: 0.6697 Acc: 0.6964\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.4302 Acc: 0.8063\n",
      "valid Loss: 0.7075 Acc: 0.6786\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.2212 Acc: 0.9368\n",
      "valid Loss: 0.7959 Acc: 0.7083\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.0455 Acc: 0.9980\n",
      "valid Loss: 0.8615 Acc: 0.6964\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.0081 Acc: 1.0000\n",
      "valid Loss: 0.8630 Acc: 0.6667\n",
      "Early stopping\n",
      "Training complete in 10m 29s\n",
      "Best val Acc: 0.714286\n",
      "Total memory   :\t 25769803776\n",
      "Allocated memory   :\t 6411460096\n",
      "Free memory   :\t\t 19358343680\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import gc\n",
    "\n",
    "num_epochs=500\n",
    "batch_size=10\n",
    "\n",
    "Nvalid=valid_targets.size\n",
    "Nmodel=len(model_list)\n",
    "est=np.zeros((Nvalid,Nmodel))\n",
    "lab=np.zeros((Nvalid,Nmodel))\n",
    "train_history=np.zeros((Nmodel,4,num_epochs))\n",
    "trained_list=[]\n",
    "\n",
    "j=0\n",
    "for model in model_list:\n",
    "    print('Training model: {:d} of {:d}'.format(j,len(model_list)))\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "\n",
    "    criterion=nn.CrossEntropyLoss(weight=class_weight.to(device))\n",
    "    #criterion=nn.BCEWithLogitsLoss()\n",
    "\n",
    "    trained_model, model_history =train_model(datasets,dataloaders,model,criterion,optimizer,scheduler,num_epochs,device)\n",
    "    trained_model=trained_model.cpu()\n",
    "    model=model.cpu()\n",
    "    \n",
    "    train_history[j,:,:]=model_history\n",
    "    \n",
    "    trained_list.append(trained_model)\n",
    "    \n",
    "    for idx,(inputs, labels) in enumerate(valid_loader):\n",
    "        trained_model=trained_model.to(device)\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = trained_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        est[idx*batch_size:idx*batch_size+batch_size,j]=preds.cpu().numpy()\n",
    "        lab[idx*batch_size:idx*batch_size+batch_size,j]=labels.cpu().numpy()\n",
    "    \n",
    "    del model\n",
    "    trained_model=trained_model.cpu()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    t = torch.cuda.get_device_properties(1).total_memory\n",
    "    r = torch.cuda.memory_reserved(1)\n",
    "    a = torch.cuda.memory_allocated(1)\n",
    "    f = t-a  # free inside reserved\n",
    "    print(f'Total memory   :\\t {t}')\n",
    "    print(f'Allocated memory   :\\t {a}')\n",
    "    print(f'Free memory   :\\t\\t {f}')\n",
    "\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc=np.zeros((Nmodel,))\n",
    "acc=np.zeros((Nmodel,))\n",
    "balacc=np.zeros((Nmodel,))\n",
    "ppv=np.zeros((Nmodel,))\n",
    "cm=np.zeros((2,2,Nmodel))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for j in range(Nmodel):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(lab[:,j], est[:,j], pos_label=1)\n",
    "    plt.plot(fpr,tpr)\n",
    "    \n",
    "    roc_auc[j] = metrics.auc(fpr, tpr)\n",
    "    acc[j] = metrics.accuracy_score(lab[:,j], est[:,j]>0.5)\n",
    "    balacc[j]= metrics.balanced_accuracy_score(lab[:,j], est[:,j]>0.5)\n",
    "    ppv[j] = metrics.precision_score(lab[:,j], est[:,j]>0.5)\n",
    "    cm[:,:,j]=metrics.confusion_matrix(lab[:,j], est[:,j]>0.5)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70707965, 0.62847949, 0.68350764, 0.67811746, 0.65229284,\n",
       "       0.63829445, 0.65229284])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74404762, 0.72619048, 0.75      , 0.76785714, 0.71428571,\n",
       "       0.71428571, 0.71428571])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70707965, 0.62847949, 0.68350764, 0.67811746, 0.65229284,\n",
       "       0.63829445, 0.65229284])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balacc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
